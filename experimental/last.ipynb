{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 85763 entries, 0 to 85762\n",
      "Data columns (total 55 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Customer_ID               85763 non-null  object \n",
      " 1   Age                       85763 non-null  float64\n",
      " 2   Annual_Income             85763 non-null  float64\n",
      " 3   Monthly_Inhand_Salary     85763 non-null  float64\n",
      " 4   Num_Bank_Accounts         85763 non-null  float64\n",
      " 5   Num_Credit_Card           85763 non-null  float64\n",
      " 6   Interest_Rate             85763 non-null  float64\n",
      " 7   Num_of_Loan               85763 non-null  float64\n",
      " 8   Delay_from_due_date       85763 non-null  float64\n",
      " 9   Num_of_Delayed_Payment    85763 non-null  float64\n",
      " 10  Changed_Credit_Limit      85763 non-null  float64\n",
      " 11  Num_Credit_Inquiries      85763 non-null  float64\n",
      " 12  Credit_Mix                85763 non-null  int64  \n",
      " 13  Outstanding_Debt          85763 non-null  float64\n",
      " 14  Credit_Utilization_Ratio  85763 non-null  float64\n",
      " 15  Credit_History_Age        85763 non-null  int64  \n",
      " 16  Payment_of_Min_Amount     85763 non-null  int64  \n",
      " 17  Total_EMI_per_month       85763 non-null  float64\n",
      " 18  Amount_invested_monthly   85763 non-null  float64\n",
      " 19  Monthly_Balance           85763 non-null  float64\n",
      " 20  Credit_Score              85763 non-null  int64  \n",
      " 21  Charge                    85763 non-null  int64  \n",
      " 22  Payment                   85763 non-null  int64  \n",
      " 23  Auto Loan                 85763 non-null  int64  \n",
      " 24  Credit-Builder Loan       85763 non-null  int64  \n",
      " 25  Debt Consolidation Loan   85763 non-null  int64  \n",
      " 26  Home Equity Loan          85763 non-null  int64  \n",
      " 27  Mortgage Loan             85763 non-null  int64  \n",
      " 28  Not Specified             85763 non-null  int64  \n",
      " 29  Payday Loan               85763 non-null  int64  \n",
      " 30  Personal Loan             85763 non-null  int64  \n",
      " 31  Student Loan              85763 non-null  int64  \n",
      " 32  Occupation_Accountant     85763 non-null  float64\n",
      " 33  Occupation_Architect      85763 non-null  float64\n",
      " 34  Occupation_Developer      85763 non-null  float64\n",
      " 35  Occupation_Doctor         85763 non-null  float64\n",
      " 36  Occupation_Engineer       85763 non-null  float64\n",
      " 37  Occupation_Entrepreneur   85763 non-null  float64\n",
      " 38  Occupation_Journalist     85763 non-null  float64\n",
      " 39  Occupation_Lawyer         85763 non-null  float64\n",
      " 40  Occupation_Manager        85763 non-null  float64\n",
      " 41  Occupation_Mechanic       85763 non-null  float64\n",
      " 42  Occupation_Media_Manager  85763 non-null  float64\n",
      " 43  Occupation_Musician       85763 non-null  float64\n",
      " 44  Occupation_Scientist      85763 non-null  float64\n",
      " 45  Occupation_Teacher        85763 non-null  float64\n",
      " 46  Occupation_Writer         85763 non-null  float64\n",
      " 47  Month_April               85763 non-null  float64\n",
      " 48  Month_August              85763 non-null  float64\n",
      " 49  Month_February            85763 non-null  float64\n",
      " 50  Month_January             85763 non-null  float64\n",
      " 51  Month_July                85763 non-null  float64\n",
      " 52  Month_June                85763 non-null  float64\n",
      " 53  Month_March               85763 non-null  float64\n",
      " 54  Month_May                 85763 non-null  float64\n",
      "dtypes: float64(39), int64(15), object(1)\n",
      "memory usage: 36.0+ MB\n",
      "   Customer_ID   Age  Annual_Income  Monthly_Inhand_Salary  Num_Bank_Accounts  \\\n",
      "0    CUS_0xd40  23.0       19114.12            1824.843333                3.0   \n",
      "1    CUS_0xd40  23.0       19114.12            1824.843333                3.0   \n",
      "2    CUS_0xd40  23.0       19114.12            1824.843333                3.0   \n",
      "3    CUS_0xd40  23.0       19114.12            1824.843333                3.0   \n",
      "4    CUS_0xd40  23.0       19114.12            1824.843333                3.0   \n",
      "5    CUS_0xd40  23.0       19114.12            1824.843333                3.0   \n",
      "6   CUS_0x21b1  28.0       34847.84            3037.986667                2.0   \n",
      "7   CUS_0x21b1  28.0       34847.84            3037.986667                2.0   \n",
      "8   CUS_0x21b1  28.0       34847.84            3037.986667                2.0   \n",
      "9   CUS_0x21b1  28.0       34847.84            3037.986667                2.0   \n",
      "10  CUS_0x21b1  28.0       34847.84            3037.986667                2.0   \n",
      "11  CUS_0x21b1  28.0       34847.84            3037.986667                2.0   \n",
      "12  CUS_0x21b1  28.0       34847.84            3037.986667                2.0   \n",
      "13  CUS_0x21b1  28.0       34847.84            3037.986667                2.0   \n",
      "14  CUS_0x2dbc  34.0      143162.64           12187.220000                1.0   \n",
      "15  CUS_0x2dbc  34.0      143162.64           12187.220000                1.0   \n",
      "16  CUS_0x2dbc  34.0      143162.64           12187.220000                1.0   \n",
      "17  CUS_0x2dbc  34.0      143162.64           12187.220000                1.0   \n",
      "18  CUS_0x2dbc  34.0      143162.64           12187.220000                1.0   \n",
      "19  CUS_0x2dbc  34.0      143162.64           12187.220000                1.0   \n",
      "\n",
      "    Num_Credit_Card  Interest_Rate  Num_of_Loan  Delay_from_due_date  \\\n",
      "0               4.0            3.0          4.0                  3.0   \n",
      "1               4.0            3.0          4.0                  3.0   \n",
      "2               4.0            3.0          4.0                  5.0   \n",
      "3               4.0            3.0          4.0                  8.0   \n",
      "4               4.0            3.0          4.0                  3.0   \n",
      "5               4.0            3.0          4.0                  3.0   \n",
      "6               4.0            6.0          1.0                  3.0   \n",
      "7               4.0            6.0          1.0                  7.0   \n",
      "8               4.0            6.0          1.0                  3.0   \n",
      "9               4.0            6.0          1.0                  3.0   \n",
      "10              4.0            6.0          1.0                  3.0   \n",
      "11              4.0            6.0          1.0                  3.0   \n",
      "12              4.0            6.0          1.0                  3.0   \n",
      "13              4.0            6.0          1.0                  3.0   \n",
      "14              5.0            8.0          3.0                  5.0   \n",
      "15              5.0            8.0          3.0                 13.0   \n",
      "16              5.0            8.0          3.0                  8.0   \n",
      "17              5.0            8.0          3.0                  8.0   \n",
      "18              5.0            8.0          3.0                 10.0   \n",
      "19              5.0            8.0          3.0                  8.0   \n",
      "\n",
      "    Num_of_Delayed_Payment  ...  Occupation_Teacher  Occupation_Writer  \\\n",
      "0                      7.0  ...                 0.0                0.0   \n",
      "1                      7.0  ...                 0.0                0.0   \n",
      "2                      4.0  ...                 0.0                0.0   \n",
      "3                      4.0  ...                 0.0                0.0   \n",
      "4                      8.0  ...                 0.0                0.0   \n",
      "5                      6.0  ...                 0.0                0.0   \n",
      "6                      4.0  ...                 1.0                0.0   \n",
      "7                      1.0  ...                 1.0                0.0   \n",
      "8                     -1.0  ...                 1.0                0.0   \n",
      "9                      3.0  ...                 1.0                0.0   \n",
      "10                     1.0  ...                 1.0                0.0   \n",
      "11                     0.0  ...                 1.0                0.0   \n",
      "12                     4.0  ...                 1.0                0.0   \n",
      "13                     4.0  ...                 1.0                0.0   \n",
      "14                     8.0  ...                 0.0                0.0   \n",
      "15                     6.0  ...                 0.0                0.0   \n",
      "16                     7.0  ...                 0.0                0.0   \n",
      "17                     5.0  ...                 0.0                0.0   \n",
      "18                     5.0  ...                 0.0                0.0   \n",
      "19                     6.0  ...                 0.0                0.0   \n",
      "\n",
      "    Month_April  Month_August  Month_February  Month_January  Month_July  \\\n",
      "0           0.0           0.0             0.0            1.0         0.0   \n",
      "1           0.0           0.0             0.0            0.0         0.0   \n",
      "2           1.0           0.0             0.0            0.0         0.0   \n",
      "3           0.0           0.0             0.0            0.0         0.0   \n",
      "4           0.0           0.0             0.0            0.0         1.0   \n",
      "5           0.0           1.0             0.0            0.0         0.0   \n",
      "6           0.0           0.0             0.0            1.0         0.0   \n",
      "7           0.0           0.0             1.0            0.0         0.0   \n",
      "8           0.0           0.0             0.0            0.0         0.0   \n",
      "9           1.0           0.0             0.0            0.0         0.0   \n",
      "10          0.0           0.0             0.0            0.0         0.0   \n",
      "11          0.0           0.0             0.0            0.0         0.0   \n",
      "12          0.0           0.0             0.0            0.0         1.0   \n",
      "13          0.0           1.0             0.0            0.0         0.0   \n",
      "14          0.0           0.0             0.0            1.0         0.0   \n",
      "15          0.0           0.0             1.0            0.0         0.0   \n",
      "16          0.0           0.0             0.0            0.0         0.0   \n",
      "17          1.0           0.0             0.0            0.0         0.0   \n",
      "18          0.0           0.0             0.0            0.0         0.0   \n",
      "19          0.0           0.0             0.0            0.0         0.0   \n",
      "\n",
      "    Month_June  Month_March  Month_May  \n",
      "0          0.0          0.0        0.0  \n",
      "1          0.0          1.0        0.0  \n",
      "2          0.0          0.0        0.0  \n",
      "3          1.0          0.0        0.0  \n",
      "4          0.0          0.0        0.0  \n",
      "5          0.0          0.0        0.0  \n",
      "6          0.0          0.0        0.0  \n",
      "7          0.0          0.0        0.0  \n",
      "8          0.0          1.0        0.0  \n",
      "9          0.0          0.0        0.0  \n",
      "10         0.0          0.0        1.0  \n",
      "11         1.0          0.0        0.0  \n",
      "12         0.0          0.0        0.0  \n",
      "13         0.0          0.0        0.0  \n",
      "14         0.0          0.0        0.0  \n",
      "15         0.0          0.0        0.0  \n",
      "16         0.0          1.0        0.0  \n",
      "17         0.0          0.0        0.0  \n",
      "18         0.0          0.0        1.0  \n",
      "19         1.0          0.0        0.0  \n",
      "\n",
      "[20 rows x 55 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "cleanedData = pd.read_csv('train_transformed.csv')\n",
    "#cleanedData.info()\n",
    "pd.set_option('display.max_columns', None)  # Show all columns\n",
    "pd.set_option('display.expand_frame_repr', False)  # Prevent line breaks\n",
    "#\n",
    "#print(cleanedData.head())\n",
    "#print the first 20 values \n",
    "print(cleanedData.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kb\\AppData\\Local\\Temp\\ipykernel_42336\\1803201993.py:5: DtypeWarning: Columns (26) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  train = pd.read_csv('train.csv')\n"
     ]
    }
   ],
   "source": [
    "# lets load the data from train.csv and test.csv files\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import pandas as pd\n",
    "\n",
    "class NumericCleaner(BaseEstimator, TransformerMixin):\n",
    "   def __init__(self):\n",
    "      self.columns_to_clean =  ['Age', 'Annual_Income', 'Num_of_Loan', 'Num_of_Delayed_Payment',\n",
    "       'Changed_Credit_Limit', 'Outstanding_Debt', 'Amount_invested_monthly', 'Monthly_Balance']\n",
    "\n",
    "   def fit(self, X, y=None):\n",
    "      # No fitting necessary for this transformer\n",
    "      return self\n",
    "\n",
    "   def transform(self, X):\n",
    "      print('Cleaning numeric columns')\n",
    "      # Make a copy of the DataFrame to avoid modifying the original data\n",
    "      X = X.copy()\n",
    "            \n",
    "      # Apply cleaning function to each specified column\n",
    "      for column in self.columns_to_clean:\n",
    "         X[column] = pd.to_numeric(X[column].str.replace(r'[^0-9.-]', '', regex=True), errors='coerce')\n",
    "\n",
    "        \n",
    "      return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "import pandas as pd\n",
    "\n",
    "class CreditHistoryTransformer(BaseEstimator, TransformerMixin):\n",
    "   def __init__(self):\n",
    "      self.column = 'Credit_History_Age'\n",
    "        \n",
    "\n",
    "   def fit(self, X, y=None): \n",
    "      assert isinstance(X, pd.DataFrame) and self.column in X.columns\n",
    "      #set number of features\n",
    "      self._n_features = X.shape[1]\n",
    "      return self\n",
    "   \n",
    "   def transform(self, X):\n",
    "      check_is_fitted(self, '_n_features')\n",
    "      assert isinstance(X, pd.DataFrame) and self.column in X.columns   \n",
    "      print('Transforming Credit_History_Age')\n",
    "      #now lets transformt the data \n",
    "      # we need to convert the verbal description to numerical values\n",
    "      # it's in this form '22 Years and 1 Months'\n",
    "      # first we change the column to string type \n",
    "      #tthen process the string to get the numerical values\n",
    "      # then multiply the years by 12 and add the months\n",
    "      X[self.column] = X[self.column].astype(str)\n",
    "\n",
    "      years = X[self.column].str.extract(r'(\\d+)\\s*Years?')[0].fillna(0).astype(int)\n",
    "      months = X[self.column].str.extract(r'(\\d+)\\s*Months?')[0].fillna(0).astype(int)\n",
    "\n",
    "    # Calculate total months\n",
    "      X[self.column] = years * 12 + months\n",
    "      return X\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "import pandas as pd\n",
    "\n",
    "class PaymentBehaviourTransformer(BaseEstimator, TransformerMixin):\n",
    "   def __init__(self):\n",
    "      self.charge_mapping = {'Low_spent': 0, 'Medium_spent': 1, 'High_spent': 2}\n",
    "      self.payment_mapping = {'Small_value_payments': 0, 'Medium_value_payments': 1, 'Large_value_payments': 2}\n",
    "      self.columns = 'Payment_Behaviour'\n",
    "\n",
    "   def fit(self, X, y=None):\n",
    "      assert isinstance(X, pd.DataFrame)\n",
    "      'Payment_Behaviour' in X.columns\n",
    "\n",
    "      return self\n",
    "   \n",
    "   def transform(self, X):\n",
    "      charge, payment = X['Payment_Behaviour'].apply(self.split_payment_behavior)\n",
    "      X['Charge'] = charge\n",
    "      X['Payment'] = payment\n",
    "      X.drop('Payment_Behaviour', axis=1, inplace=True)\n",
    "      print('Transforming Payment_Behaviour')\n",
    "      return X\n",
    "   \n",
    "   def split_payment_behavior(self, value):\n",
    "      if isinstance(value, str):\n",
    "         # Split the value into components based on the underscore\n",
    "         parts = value.split('_')\n",
    "         \n",
    "         # The first part corresponds to charge, and the last two parts correspond to payment\n",
    "         charge_part = '_'.join(parts[:2])  # Join the first two parts for charge\n",
    "         payment_part = '_'.join(parts[2:])  # Join the rest for payment\n",
    "         \n",
    "         # Get the corresponding numerical values from the mappings\n",
    "         charge_value = self.charge_mapping.get(charge_part, np.nan)\n",
    "         payment_value = self.payment_mapping.get(payment_part, np.nan)\n",
    "         \n",
    "         return pd.Series([charge_value, payment_value])\n",
    "      else:\n",
    "         return pd.Series([np.nan, np.nan])  # Return NaN for non-string values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "import pandas as pd\n",
    "\n",
    "class LoanType(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.ml_binarizer = MultiLabelBinarizer()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        assert isinstance(X, pd.DataFrame) and 'Type_of_Loan' in X.columns\n",
    "        # Ensure the column is treated as a string and handle NaN values\n",
    "        loan_types = X['Type_of_Loan'].fillna('Not Specified').astype(str).str.split(', ')\n",
    "        # Clean up the loan types to remove unwanted phrases\n",
    "        loan_types = loan_types.apply(lambda x: [item.strip() for item in x if 'and' not in item])\n",
    "        self.ml_binarizer.fit(loan_types)      \n",
    "        self._n_features = len(self.ml_binarizer.classes_)\n",
    "        return self \n",
    "\n",
    "    def transform(self, X):\n",
    "        # Check if the transformer has been fitted\\\n",
    "        print('Transforming Loan Type')\n",
    "        check_is_fitted(self, '_n_features')\n",
    "        assert isinstance(X, pd.DataFrame) and 'Type_of_Loan' in X.columns\n",
    "        # Ensure the column is treated as a string and handle NaN values\n",
    "        loan_types = X['Type_of_Loan'].fillna('Not Specified').astype(str).str.split(', ')\n",
    "        # Clean up the loan types to remove unwanted phrases\n",
    "        loan_types = loan_types.apply(lambda x: [item.strip() for item in x if 'and' not in item])\n",
    "        loan_type_dummies = self.ml_binarizer.transform(loan_types)\n",
    "        \n",
    "        # Create a DataFrame for the binary columns\n",
    "        loan_type_df = pd.DataFrame(loan_type_dummies, columns=self.ml_binarizer.classes_, index=X.index)\n",
    "        \n",
    "        # Concatenate the new binary columns with the original DataFrame\n",
    "        X = pd.concat([X, loan_type_df], axis=1)\n",
    "        X.drop('Type_of_Loan', axis=1, inplace=True)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import NAN\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "\n",
    "class HiLoImputer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, lo, hi, columnName):\n",
    "        self.hi = hi\n",
    "        self.lo = lo\n",
    "        self.columnName = columnName\n",
    "        self.isCategory = False\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        assert isinstance(X, pd.DataFrame) and len(X.columns) > 1\n",
    "        assert self.columnName in X.columns\n",
    "        \n",
    "        # Check if the column is categorical\n",
    "        self.isCategory = X[self.columnName].dtype.name == 'object' or X[self.columnName].dtype.name == 'category'\n",
    "        if self.isCategory:\n",
    "            #convert to category\n",
    "\n",
    "            self.categories_ = X[self.columnName].astype('category').cat.categories\n",
    "\n",
    "        # Store the number of features\n",
    "        self._n_features = X.shape[1]\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        check_is_fitted(self, '_n_features')\n",
    "        assert isinstance(X, pd.DataFrame) and X.shape[1] == self._n_features\n",
    "        print('Imputing HiLo values')\n",
    "\n",
    "        if self.isCategory:\n",
    "            # Convert categories to codes for hi/lo processing\n",
    "            X[self.columnName] = X[self.columnName].astype('category').cat.codes\n",
    "\n",
    "            # Apply hi/lo bounds, setting out-of-bounds to NaN\n",
    "            X[self.columnName] = np.where(\n",
    "                (X[self.columnName] > self.hi) | (X[self.columnName] < self.lo), \n",
    "                np.nan, X[self.columnName]\n",
    "            )\n",
    "            \n",
    "            # Replace NaN values with the mode per Customer_ID group\n",
    "            X[self.columnName] = X.groupby('Customer_ID', group_keys=False)[self.columnName].apply(\n",
    "                lambda x: x.fillna(x.mode().iloc[0] if not x.mode().empty else x)\n",
    "            )\n",
    "\n",
    "            # Convert back to categories\n",
    "            X[self.columnName] = pd.Categorical.from_codes(\n",
    "                X[self.columnName].fillna(-1).astype(int), categories=self.categories_, ordered=True\n",
    "            ).remove_unused_categories()\n",
    "\n",
    "        else:\n",
    "            # Apply hi/lo bounds for numerical data\n",
    "            X[self.columnName] = np.where(\n",
    "                (X[self.columnName] > self.hi) | (X[self.columnName] < self.lo), \n",
    "                np.nan, X[self.columnName]\n",
    "            )\n",
    "\n",
    "            # Replace NaN values with the mode per Customer_ID group\n",
    "            X[self.columnName] = X.groupby('Customer_ID', group_keys=False)[self.columnName].apply(\n",
    "                lambda x: x.fillna(x.mode().iloc[0] if not x.mode().empty else x)\n",
    "            )\n",
    "\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class toCategoryCodes(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "       pass\n",
    "      \n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        assert isinstance(X, pd.DataFrame) and len(X.columns) > 1\n",
    "       # assert self.columnName in X.columns\n",
    "       # lets get the categorical columns\n",
    "        self.columnName = X.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "        # Store the number of features\n",
    "        self._n_features = X.shape[1]\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        check_is_fitted(self, '_n_features')\n",
    "        assert isinstance(X, pd.DataFrame) and X.shape[1] == self._n_features\n",
    "        print('Converting to category')\n",
    "        for column in self.columnName:\n",
    "            #convert to cat codes\n",
    "            X[column] = X[column].astype('category').cat.codes\n",
    "            \n",
    "         #X[self.columnName] = X[self.columnName].astype('category')\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HiLoTransformer(BaseEstimator, TransformerMixin):\n",
    "   def __init__(self, bounds):\n",
    "      self.bounds = bounds \n",
    "      \n",
    "   \n",
    "   def fit(self, X):\n",
    "      assert isinstance(X, pd.DataFrame)\n",
    "      self._n_features = X.shape[1]\n",
    "      self._feature_names = X.columns\n",
    " \n",
    "      return self\n",
    "   \n",
    "   def transform(self, X):\n",
    "      check_is_fitted(self, '_n_features')\n",
    "      assert isinstance(X, pd.DataFrame) and X.shape[1] == self._n_features\n",
    "      print('Transforming HiLo values')\n",
    "      \n",
    "      for column, bounds in self.bounds.items():\n",
    "         isCategory = X[column].dtype.name == 'category' or X[column].dtype.name == 'object'\n",
    "  \n",
    "         if  X[column].dtype.name == 'category' or X[column].dtype.name == 'object':\n",
    "            X[column] = X[column].astype('category')\n",
    "\n",
    "            categories = X[column].cat.categories\n",
    "            X[column] = X[column].astype('category').cat.codes\n",
    "\n",
    "         X[column] = np.where(\n",
    "               (X[column] > bounds['hi']) | (X[column] < bounds['lo']), \n",
    "               np.nan, X[column]\n",
    "         )\n",
    "         X[column] = X.groupby('Customer_ID', group_keys=False)[column].apply(\n",
    "               lambda x: x.fillna(x.mode().iloc[0] if not x.mode().empty else x)\n",
    "         )\n",
    "         #convert back to categorical\n",
    "         if isCategory:\n",
    "            X[column] = pd.Categorical.from_codes(\n",
    "               X[column].fillna(-1).astype(int), categories=categories, ordered=True\n",
    "            ).remove_unused_categories()\n",
    "            X[column] = X[column].astype('category')\n",
    "            print(X[column].value_counts())\n",
    "\n",
    "      return X\n",
    "\n",
    "   def get_feature_names_out(self, input_features=None):\n",
    "      if input_features is None:\n",
    "         return self._feature_names\n",
    "      return input_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "class OccupationOneHotEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.onehot = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "        print('OccupationOneHotEncoder')\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        # Handle missing data by filling it with a placeholder\n",
    "        \n",
    "      #  X['Occupation'] = X['Occupation'].astype(str)\n",
    "        self.onehot.fit(X[['Occupation']])\n",
    "        self.feature_names_out = self.onehot.get_feature_names_out(['Occupation'])\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        encoded = self.onehot.transform(X[['Occupation']])\n",
    "        encoded_df = pd.DataFrame(encoded, columns=self.onehot.get_feature_names_out(['Occupation']))\n",
    "        X = X.reset_index(drop=True)\n",
    "        return pd.concat([X, encoded_df], axis=1).drop(columns=['Occupation'])\n",
    "\n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        if input_features is None:\n",
    "            return self.feature_names_out\n",
    "        return input_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DropColumnsTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        X = pd.DataFrame(X)\n",
    "        self.feature_names_out_ = [col for col in X.columns if col not in self.columns]\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            # Use default column names if X is a numpy array\n",
    "            print('Transforming DropColumns')\n",
    "            X = pd.DataFrame(X)\n",
    "\n",
    "        X.drop(columns=self.columns, inplace=True, errors='ignore')\n",
    "        X.info()\n",
    "        return X\n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        return self.feature_names_out_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "hi_lo_bounds = {\n",
    "    # Numerical Columns\n",
    "    'Age': {'lo': 0, 'hi': 100},\n",
    "    'Annual_Income': {'lo': 5000, 'hi': 500000},\n",
    "    'Monthly_Inhand_Salary': {'lo': 500, 'hi': 30000},\n",
    "    'Num_Bank_Accounts': {'lo': 0, 'hi': 20},\n",
    "    'Num_Credit_Card': {'lo': 0, 'hi': 15},\n",
    "    'Interest_Rate': {'lo': 0, 'hi': 50},\n",
    "    'Delay_from_due_date': {'lo': 0, 'hi': 100},\n",
    "    'Num_Credit_Inquiries': {'lo': 0, 'hi': 30},\n",
    "    'Changed_Credit_Limit': {'lo': 0, 'hi': 30},  # Bounds after converting to numeric\n",
    "    'Num_of_Loan': {'lo': 0, 'hi': 10},  # Bounds after converting to numeric\n",
    "    \n",
    "    # Categorical Columns (ordered)\n",
    "    'Credit_Mix': {'lo': 0, 'hi': 2},  # Assuming \"Bad\" = 0, \"Standard\" = 1, \"Good\" = 2\n",
    "\n",
    "    # Categorical Column (nominal)\n",
    "    'Occupation': {'lo': 0, 'hi': 14}  # No bounds, only impute missing values\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformer to drop Nan rows\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import pandas as pd\n",
    "\n",
    "class DropNanRows(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        print('Dropping Nan rows')\n",
    "        return X.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets make a month transformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import pandas as pd\n",
    "\n",
    "class MonthTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        print('Transforming Month')\n",
    "        X['Month'] = X['Month'].astype('category').cat.codes\n",
    "        X['Month_sin'] = np.sin(2 * np.pi * X['Month'] + 1 / 12)\n",
    "        X['Month_cos'] = np.cos(2 * np.pi * X['Month'] + 1 / 12)\n",
    "        X.drop(columns=['Month'], inplace=True)\n",
    "        return X    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OccupationOneHotEncoder\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "pipeline = Pipeline(steps= [\n",
    "   ('NumericCleaner', NumericCleaner()),\n",
    "   \n",
    "   ('CreditHistoryTransformer', CreditHistoryTransformer()),\n",
    "   ('PaymentBehaviourTransformer', PaymentBehaviourTransformer()),\n",
    "   ('LoanType', LoanType()),\n",
    "   ('HiLoTransformer', HiLoTransformer(bounds=hi_lo_bounds)), \n",
    "   ('OccupationOneHotEncoder', OccupationOneHotEncoder()),\n",
    "   ('DropColumnsTransformer', DropColumnsTransformer(columns=['Customer_ID', 'ID', 'Name', 'SSN'])),\n",
    "    \n",
    "   ('toCategoryCodes', toCategoryCodes()),('MonthTransformer', MonthTransformer()),\n",
    "    ('DropNanRows', DropNanRows())\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier Validation Accuracy: 0.7754605723423393\n",
      "Voting Classifier Test Accuracy: 0.7784212367367562\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, VotingClassifier\n",
    "\n",
    "# Combine RandomForest and GradientBoosting\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', RandomForestClassifier(**{'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'bootstrap': False, 'random_state': 42})),\n",
    "        ('gb', GradientBoostingClassifier(**{'n_estimators': 200, 'max_depth': 10, 'learning_rate': 0.1, 'random_state': 42}))\n",
    "    ],\n",
    "    voting='soft'  # Use 'soft' voting for better probabilities\n",
    ")\n",
    "\n",
    "# Train and evaluate the ensemble\n",
    "voting_clf.fit(X_train, y_train)\n",
    "voting_val_accuracy = accuracy_score(y_val, voting_clf.predict(X_val))\n",
    "voting_test_accuracy = accuracy_score(y_test, voting_clf.predict(X_test))\n",
    "\n",
    "print(f\"Voting Classifier Validation Accuracy: {voting_val_accuracy}\")\n",
    "print(f\"Voting Classifier Test Accuracy: {voting_test_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', RandomForestClassifier(**{'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'bootstrap': False, 'random_state': 42})),\n",
    "        ('gb', GradientBoostingClassifier(**{'n_estimators': 200, 'max_depth': 10, 'learning_rate': 0.1, 'random_state': 42}))\n",
    "    ],\n",
    "    final_estimator=LogisticRegression()  # Meta-model\n",
    ")\n",
    "\n",
    "# Train and evaluate the stacked model\n",
    "stacking_clf.fit(X_train, y_train)\n",
    "stacking_val_accuracy = accuracy_score(y_val, stacking_clf.predict(X_val))\n",
    "stacking_test_accuracy = accuracy_score(y_test, stacking_clf.predict(X_test))\n",
    "\n",
    "print(f\"Stacking Classifier Validation Accuracy: {stacking_val_accuracy}\")\n",
    "print(f\"Stacking Classifier Test Accuracy: {stacking_test_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#processed_train = pipeline.fit_transform(train)\n",
    "#now lets prepare the transformed to be used in a neural network\n",
    "#we need to scale the data\n",
    "#lets use  minmax scaling \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X = processed_train.drop(columns=['Credit_Score'])\n",
    "#scaler.fit_transform(processed_train.drop(columns=['Credit_Score']))\n",
    "y = processed_train['Credit_Score']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# create test and train data and validation data\n",
    "# First, split the data into 70% training and 30% temporary (which will be split into validation and test sets)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Then, split the temporary set into 50% validation and 50% test, which results in 15% each of the original data\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 85763 entries, 0 to 98303\n",
      "Data columns (total 47 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Age                       85763 non-null  float64\n",
      " 1   Annual_Income             85763 non-null  float64\n",
      " 2   Monthly_Inhand_Salary     85763 non-null  float64\n",
      " 3   Num_Bank_Accounts         85763 non-null  float64\n",
      " 4   Num_Credit_Card           85763 non-null  float64\n",
      " 5   Interest_Rate             85763 non-null  float64\n",
      " 6   Num_of_Loan               85763 non-null  float64\n",
      " 7   Delay_from_due_date       85763 non-null  float64\n",
      " 8   Num_of_Delayed_Payment    85763 non-null  float64\n",
      " 9   Changed_Credit_Limit      85763 non-null  float64\n",
      " 10  Num_Credit_Inquiries      85763 non-null  float64\n",
      " 11  Credit_Mix                85763 non-null  int8   \n",
      " 12  Outstanding_Debt          85763 non-null  float64\n",
      " 13  Credit_Utilization_Ratio  85763 non-null  float64\n",
      " 14  Credit_History_Age        85763 non-null  int32  \n",
      " 15  Payment_of_Min_Amount     85763 non-null  int8   \n",
      " 16  Total_EMI_per_month       85763 non-null  float64\n",
      " 17  Amount_invested_monthly   85763 non-null  float64\n",
      " 18  Monthly_Balance           85763 non-null  float64\n",
      " 19  Charge                    85763 non-null  int64  \n",
      " 20  Payment                   85763 non-null  int64  \n",
      " 21  Auto Loan                 85763 non-null  int32  \n",
      " 22  Credit-Builder Loan       85763 non-null  int32  \n",
      " 23  Debt Consolidation Loan   85763 non-null  int32  \n",
      " 24  Home Equity Loan          85763 non-null  int32  \n",
      " 25  Mortgage Loan             85763 non-null  int32  \n",
      " 26  Not Specified             85763 non-null  int32  \n",
      " 27  Payday Loan               85763 non-null  int32  \n",
      " 28  Personal Loan             85763 non-null  int32  \n",
      " 29  Student Loan              85763 non-null  int32  \n",
      " 30  Occupation_Accountant     85763 non-null  float64\n",
      " 31  Occupation_Architect      85763 non-null  float64\n",
      " 32  Occupation_Developer      85763 non-null  float64\n",
      " 33  Occupation_Doctor         85763 non-null  float64\n",
      " 34  Occupation_Engineer       85763 non-null  float64\n",
      " 35  Occupation_Entrepreneur   85763 non-null  float64\n",
      " 36  Occupation_Journalist     85763 non-null  float64\n",
      " 37  Occupation_Lawyer         85763 non-null  float64\n",
      " 38  Occupation_Manager        85763 non-null  float64\n",
      " 39  Occupation_Mechanic       85763 non-null  float64\n",
      " 40  Occupation_Media_Manager  85763 non-null  float64\n",
      " 41  Occupation_Musician       85763 non-null  float64\n",
      " 42  Occupation_Scientist      85763 non-null  float64\n",
      " 43  Occupation_Teacher        85763 non-null  float64\n",
      " 44  Occupation_Writer         85763 non-null  float64\n",
      " 45  Month_sin                 85763 non-null  float64\n",
      " 46  Month_cos                 85763 non-null  float64\n",
      "dtypes: float64(33), int32(10), int64(2), int8(2)\n",
      "memory usage: 27.0 MB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning numeric columns\n",
      "Transforming Credit_History_Age\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m processed_train \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#now lets prepare the transformed to be used in a neural network\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#we need to scale the data\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#lets use  minmax scaling \u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MinMaxScaler\n",
      "File \u001b[1;32mc:\\Users\\kb\\anaconda3\\envs\\test-env\\lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\kb\\anaconda3\\envs\\test-env\\lib\\site-packages\\sklearn\\pipeline.py:533\u001b[0m, in \u001b[0;36mPipeline.fit_transform\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    490\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model and transform with the final estimator.\u001b[39;00m\n\u001b[0;32m    491\u001b[0m \n\u001b[0;32m    492\u001b[0m \u001b[38;5;124;03mFit all the transformers one after the other and sequentially transform\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    530\u001b[0m \u001b[38;5;124;03m    Transformed samples.\u001b[39;00m\n\u001b[0;32m    531\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    532\u001b[0m routed_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_method_params(method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m, props\u001b[38;5;241m=\u001b[39mparams)\n\u001b[1;32m--> 533\u001b[0m Xt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    535\u001b[0m last_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator\n\u001b[0;32m    536\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_message(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n",
      "File \u001b[1;32mc:\\Users\\kb\\anaconda3\\envs\\test-env\\lib\\site-packages\\sklearn\\pipeline.py:406\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[1;34m(self, X, y, routed_params)\u001b[0m\n\u001b[0;32m    404\u001b[0m     cloned_transformer \u001b[38;5;241m=\u001b[39m clone(transformer)\n\u001b[0;32m    405\u001b[0m \u001b[38;5;66;03m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[1;32m--> 406\u001b[0m X, fitted_transformer \u001b[38;5;241m=\u001b[39m \u001b[43mfit_transform_one_cached\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    407\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcloned_transformer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    408\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    409\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    410\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    411\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage_clsname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPipeline\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    412\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_idx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    413\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    414\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    415\u001b[0m \u001b[38;5;66;03m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;66;03m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[0;32m    417\u001b[0m \u001b[38;5;66;03m# from the cache.\u001b[39;00m\n\u001b[0;32m    418\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[step_idx] \u001b[38;5;241m=\u001b[39m (name, fitted_transformer)\n",
      "File \u001b[1;32mc:\\Users\\kb\\anaconda3\\envs\\test-env\\lib\\site-packages\\joblib\\memory.py:312\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 312\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\kb\\anaconda3\\envs\\test-env\\lib\\site-packages\\sklearn\\pipeline.py:1310\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, params)\u001b[0m\n\u001b[0;32m   1308\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[0;32m   1309\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1310\u001b[0m         res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit_transform(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m, {}))\n\u001b[0;32m   1311\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1312\u001b[0m         res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m, {}))\u001b[38;5;241m.\u001b[39mtransform(\n\u001b[0;32m   1313\u001b[0m             X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransform\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\n\u001b[0;32m   1314\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\kb\\anaconda3\\envs\\test-env\\lib\\site-packages\\sklearn\\utils\\_set_output.py:316\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 316\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    318\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    319\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    320\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    321\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    322\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\kb\\anaconda3\\envs\\test-env\\lib\\site-packages\\sklearn\\base.py:1098\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m   1083\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1084\u001b[0m             (\n\u001b[0;32m   1085\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis object (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) has a `transform`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1093\u001b[0m             \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[0;32m   1094\u001b[0m         )\n\u001b[0;32m   1096\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1097\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[1;32m-> 1098\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1100\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m   1101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32mc:\\Users\\kb\\anaconda3\\envs\\test-env\\lib\\site-packages\\sklearn\\utils\\_set_output.py:316\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 316\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    318\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    319\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    320\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    321\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    322\u001b[0m         )\n",
      "Cell \u001b[1;32mIn[7], line 18\u001b[0m, in \u001b[0;36mPaymentBehaviourTransformer.transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m---> 18\u001b[0m    charge, payment \u001b[38;5;241m=\u001b[39m \u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPayment_Behaviour\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit_payment_behavior\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m    X[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCharge\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m charge\n\u001b[0;32m     20\u001b[0m    X[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPayment\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m payment\n",
      "File \u001b[1;32mc:\\Users\\kb\\anaconda3\\envs\\test-env\\lib\\site-packages\\pandas\\core\\series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4800\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4918\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4922\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m-> 4924\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kb\\anaconda3\\envs\\test-env\\lib\\site-packages\\pandas\\core\\apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[0;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kb\\anaconda3\\envs\\test-env\\lib\\site-packages\\pandas\\core\\apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[0;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Users\\kb\\anaconda3\\envs\\test-env\\lib\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kb\\anaconda3\\envs\\test-env\\lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1747\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[7], line 38\u001b[0m, in \u001b[0;36mPaymentBehaviourTransformer.split_payment_behavior\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m     35\u001b[0m    charge_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcharge_mapping\u001b[38;5;241m.\u001b[39mget(charge_part, np\u001b[38;5;241m.\u001b[39mnan)\n\u001b[0;32m     36\u001b[0m    payment_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpayment_mapping\u001b[38;5;241m.\u001b[39mget(payment_part, np\u001b[38;5;241m.\u001b[39mnan)\n\u001b[1;32m---> 38\u001b[0m    \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSeries\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcharge_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpayment_value\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     40\u001b[0m    \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mSeries([np\u001b[38;5;241m.\u001b[39mnan, np\u001b[38;5;241m.\u001b[39mnan])\n",
      "File \u001b[1;32mc:\\Users\\kb\\anaconda3\\envs\\test-env\\lib\\site-packages\\pandas\\core\\series.py:592\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[1;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[0;32m    589\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    590\u001b[0m         data \u001b[38;5;241m=\u001b[39m SingleArrayManager\u001b[38;5;241m.\u001b[39mfrom_array(data, index)\n\u001b[1;32m--> 592\u001b[0m \u001b[43mNDFrame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    593\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m=\u001b[39m name\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_axis(\u001b[38;5;241m0\u001b[39m, index)\n",
      "File \u001b[1;32mc:\\Users\\kb\\anaconda3\\envs\\test-env\\lib\\site-packages\\pandas\\core\\generic.py:283\u001b[0m, in \u001b[0;36mNDFrame.__init__\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    281\u001b[0m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_item_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\n\u001b[0;32m    282\u001b[0m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_attrs\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\n\u001b[1;32m--> 283\u001b[0m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_flags\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mFlags\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallows_duplicate_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\kb\\anaconda3\\envs\\test-env\\lib\\site-packages\\pandas\\core\\flags.py:53\u001b[0m, in \u001b[0;36mFlags.__init__\u001b[1;34m(self, obj, allows_duplicate_labels)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, obj: NDFrame, \u001b[38;5;241m*\u001b[39m, allows_duplicate_labels: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_allows_duplicate_labels \u001b[38;5;241m=\u001b[39m allows_duplicate_labels\n\u001b[1;32m---> 53\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_obj \u001b[38;5;241m=\u001b[39m \u001b[43mweakref\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "processed_train = pipeline.fit_transform(train)\n",
    "#now lets prepare the transformed to be used in a neural network\n",
    "#we need to scale the data\n",
    "#lets use  minmax scaling \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X = scaler.fit_transform(processed_train.drop(columns=['Credit_Score']))\n",
    "y = processed_train['Credit_Score']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4416081350244385\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multiclass and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m rfg\u001b[38;5;241m.\u001b[39mscore(X_test, y_test)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(accuracy)\n\u001b[1;32m---> 19\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m \u001b[43maccuracy_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(accuracy)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(mean_squared_error(y_test, y_pred))\n",
      "File \u001b[1;32mc:\\Users\\kb\\anaconda3\\envs\\test-env\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\kb\\anaconda3\\envs\\test-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:231\u001b[0m, in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    229\u001b[0m xp, _, device \u001b[38;5;241m=\u001b[39m get_namespace_and_device(y_true, y_pred, sample_weight)\n\u001b[0;32m    230\u001b[0m \u001b[38;5;66;03m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[1;32m--> 231\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\kb\\anaconda3\\envs\\test-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:112\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m    109\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_type) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 112\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    113\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification metrics can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt handle a mix of \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m targets\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    114\u001b[0m             type_true, type_pred\n\u001b[0;32m    115\u001b[0m         )\n\u001b[0;32m    116\u001b[0m     )\n\u001b[0;32m    118\u001b[0m \u001b[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[0;32m    119\u001b[0m y_type \u001b[38;5;241m=\u001b[39m y_type\u001b[38;5;241m.\u001b[39mpop()\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass and continuous targets"
     ]
    }
   ],
   "source": [
    "# use a random forest regressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#import accuracy\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "rfg = RandomForestRegressor(random_state=42)\n",
    "rfg.fit(X_train, y_train)\n",
    "y_pred = rfg.predict(X_test)\n",
    "\n",
    "#print accuracy\n",
    "\n",
    "accuracy = rfg.score(X_test, y_test)\n",
    "print(accuracy)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(accuracy)\n",
    "\n",
    "print(mean_squared_error(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#processed_train = pipeline.fit_transform(train)\n",
    "#now lets prepare the transformed to be used in a neural network\n",
    "#we need to scale the data\n",
    "#lets use  scaling to force the range of the data to be between 0 and 1\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(processed_train.drop(columns=['Credit_Score']))\n",
    "y = processed_train['Credit_Score']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.4476205640749656\n",
      "RMSE: 0.6690445157648074\n",
      "accuracy: 0.23959076461649564\n"
     ]
    }
   ],
   "source": [
    "#lets use a MLP regressor to predict the credit score\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "mlp = MLPRegressor(hidden_layer_sizes=(100, 100,100), max_iter=1000, random_state=42)\n",
    "mlp.fit(X_train, y_train)\n",
    "y_pred = mlp.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print('MSE:', mse)\n",
    "print('RMSE:', np.sqrt(mse))\n",
    "print('accuracy:', mlp.score(X_test, y_test))   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Cross Validation Score: -0.670064012\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "cv_scores = [-0.66086843, -0.68539168, -0.67095262, -0.66277817, -0.67032916]\n",
    "mean_cv_score = np.mean(cv_scores)\n",
    "print('Mean Cross Validation Score:', mean_cv_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.3309885248826988\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multiclass and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 9\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining Accuracy:\u001b[39m\u001b[38;5;124m'\u001b[39m, mlp\u001b[38;5;241m.\u001b[39mscore(X_test, y_test))\n\u001b[1;32m----> 9\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m \u001b[43maccuracy_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy:\u001b[39m\u001b[38;5;124m'\u001b[39m, accuracy)\n",
      "File \u001b[1;32mc:\\Users\\kb\\anaconda3\\envs\\test-env\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\kb\\anaconda3\\envs\\test-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:231\u001b[0m, in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    229\u001b[0m xp, _, device \u001b[38;5;241m=\u001b[39m get_namespace_and_device(y_true, y_pred, sample_weight)\n\u001b[0;32m    230\u001b[0m \u001b[38;5;66;03m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[1;32m--> 231\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\kb\\anaconda3\\envs\\test-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:112\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m    109\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_type) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 112\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    113\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification metrics can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt handle a mix of \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m targets\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    114\u001b[0m             type_true, type_pred\n\u001b[0;32m    115\u001b[0m         )\n\u001b[0;32m    116\u001b[0m     )\n\u001b[0;32m    118\u001b[0m \u001b[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[0;32m    119\u001b[0m y_type \u001b[38;5;241m=\u001b[39m y_type\u001b[38;5;241m.\u001b[39mpop()\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass and continuous targets"
     ]
    }
   ],
   "source": [
    "#lets print the accuracy of the model on the training data\n",
    "#from sklearn.base import accuracy_score\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "print('Training Accuracy:', mlp.score(X_test, y_test))\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print('Accuracy:', accuracy)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score: [-0.66086843 -0.68539168 -0.67095262 -0.66277817 -0.67032916]\n"
     ]
    }
   ],
   "source": [
    "print('Cross Validation Score:', cross_val_score(mlp, X, y, cv=5, scoring='neg_mean_squared_error'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets try an MLPclassifier to predict the credit score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100, 100), max_iter=1000, random_state=42)\n",
    "mlp.fit(X_train, y_train)\n",
    "y_pred = mlp.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)\n",
    "#print('Cross Validation Score:', cross_val_score(mlp, X, y, cv=5, scoring='accuracy'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7635399055558795\n",
      "Cross Validation Score: [0.59179152 0.58252201 0.59400688 0.59835588 0.58984375]\n"
     ]
    }
   ],
   "source": [
    "#lets try an MLPclassifier to predict the credit score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100, 100), max_iter=1000, random_state=42)\n",
    "mlp.fit(X_train, y_train)\n",
    "y_pred = mlp.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)\n",
    "print('Cross Validation Score:', cross_val_score(mlp, X, y, cv=5, scoring='accuracy'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OccupationOneHotEncoder\n",
      "Running NumericCleaner\n",
      "Cleaning numeric columns\n",
      "Completed NumericCleaner\n",
      "Running CreditHistoryTransformer\n",
      "Transforming Credit_History_Age\n",
      "Completed CreditHistoryTransformer\n",
      "Running PaymentBehaviourTransformer\n",
      "Transforming Payment_Behaviour\n",
      "Completed PaymentBehaviourTransformer\n",
      "Running LoanType\n",
      "Transforming Loan Type\n",
      "Completed LoanType\n",
      "Running HiLoTransformer\n",
      "Transforming HiLo values\n",
      "Credit_Mix\n",
      "Standard    45848\n",
      "Good        30384\n",
      "Bad         23768\n",
      "Name: count, dtype: int64\n",
      "Occupation\n",
      "Lawyer           7096\n",
      "Engineer         6864\n",
      "Architect        6824\n",
      "Mechanic         6776\n",
      "Accountant       6744\n",
      "Scientist        6744\n",
      "Developer        6720\n",
      "Media_Manager    6720\n",
      "Teacher          6672\n",
      "Entrepreneur     6648\n",
      "Doctor           6568\n",
      "Journalist       6536\n",
      "Manager          6432\n",
      "Musician         6352\n",
      "Writer           6304\n",
      "Name: count, dtype: int64\n",
      "Completed HiLoTransformer\n",
      "Running OccupationOneHotEncoder\n",
      "Completed OccupationOneHotEncoder\n",
      "Running DropColumnsTransformer\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 50 columns):\n",
      " #   Column                    Non-Null Count   Dtype   \n",
      "---  ------                    --------------   -----   \n",
      " 0   ID                        100000 non-null  object  \n",
      " 1   Month                     100000 non-null  object  \n",
      " 2   Name                      90015 non-null   object  \n",
      " 3   Age                       100000 non-null  float64 \n",
      " 4   SSN                       100000 non-null  object  \n",
      " 5   Annual_Income             100000 non-null  float64 \n",
      " 6   Monthly_Inhand_Salary     99336 non-null   float64 \n",
      " 7   Num_Bank_Accounts         100000 non-null  float64 \n",
      " 8   Num_Credit_Card           100000 non-null  float64 \n",
      " 9   Interest_Rate             100000 non-null  float64 \n",
      " 10  Num_of_Loan               100000 non-null  float64 \n",
      " 11  Delay_from_due_date       100000 non-null  float64 \n",
      " 12  Num_of_Delayed_Payment    92998 non-null   float64 \n",
      " 13  Changed_Credit_Limit      100000 non-null  float64 \n",
      " 14  Num_Credit_Inquiries      100000 non-null  float64 \n",
      " 15  Credit_Mix                100000 non-null  category\n",
      " 16  Outstanding_Debt          100000 non-null  float64 \n",
      " 17  Credit_Utilization_Ratio  100000 non-null  float64 \n",
      " 18  Credit_History_Age        100000 non-null  int32   \n",
      " 19  Payment_of_Min_Amount     100000 non-null  object  \n",
      " 20  Total_EMI_per_month       100000 non-null  float64 \n",
      " 21  Amount_invested_monthly   95521 non-null   float64 \n",
      " 22  Monthly_Balance           97132 non-null   float64 \n",
      " 23  Credit_Score              100000 non-null  object  \n",
      " 24  Charge                    100000 non-null  int64   \n",
      " 25  Payment                   100000 non-null  int64   \n",
      " 26  Auto Loan                 100000 non-null  int32   \n",
      " 27  Credit-Builder Loan       100000 non-null  int32   \n",
      " 28  Debt Consolidation Loan   100000 non-null  int32   \n",
      " 29  Home Equity Loan          100000 non-null  int32   \n",
      " 30  Mortgage Loan             100000 non-null  int32   \n",
      " 31  Not Specified             100000 non-null  int32   \n",
      " 32  Payday Loan               100000 non-null  int32   \n",
      " 33  Personal Loan             100000 non-null  int32   \n",
      " 34  Student Loan              100000 non-null  int32   \n",
      " 35  Occupation_Accountant     100000 non-null  float64 \n",
      " 36  Occupation_Architect      100000 non-null  float64 \n",
      " 37  Occupation_Developer      100000 non-null  float64 \n",
      " 38  Occupation_Doctor         100000 non-null  float64 \n",
      " 39  Occupation_Engineer       100000 non-null  float64 \n",
      " 40  Occupation_Entrepreneur   100000 non-null  float64 \n",
      " 41  Occupation_Journalist     100000 non-null  float64 \n",
      " 42  Occupation_Lawyer         100000 non-null  float64 \n",
      " 43  Occupation_Manager        100000 non-null  float64 \n",
      " 44  Occupation_Mechanic       100000 non-null  float64 \n",
      " 45  Occupation_Media_Manager  100000 non-null  float64 \n",
      " 46  Occupation_Musician       100000 non-null  float64 \n",
      " 47  Occupation_Scientist      100000 non-null  float64 \n",
      " 48  Occupation_Teacher        100000 non-null  float64 \n",
      " 49  Occupation_Writer         100000 non-null  float64 \n",
      "dtypes: category(1), float64(31), int32(10), int64(2), object(6)\n",
      "memory usage: 33.7+ MB\n",
      "Completed DropColumnsTransformer\n"
     ]
    }
   ],
   "source": [
    "steps = [\n",
    "    ('NumericCleaner', NumericCleaner()),\n",
    "    ('CreditHistoryTransformer', CreditHistoryTransformer()),\n",
    "    ('PaymentBehaviourTransformer', PaymentBehaviourTransformer()),\n",
    "    ('LoanType', LoanType()),\n",
    "    ('HiLoTransformer', HiLoTransformer(bounds=hi_lo_bounds)),\n",
    "    ('OccupationOneHotEncoder', OccupationOneHotEncoder()),\n",
    "    ('DropColumnsTransformer', DropColumnsTransformer(columns=['Customer_ID', 'ID', 'Name', 'SSN']))\n",
    "]\n",
    "train_copy = train.copy()\n",
    "\n",
    "for name, transformer in steps:\n",
    "    try:\n",
    "        print(f\"Running {name}\")\n",
    "        train_copy = transformer.fit_transform(train_copy)\n",
    "        print(f\"Completed {name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error in {name}: {e}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.random.set_seed(42)\n",
    "norm_layer = tf.keras.layers.Normalization()\n",
    "hidden_layer1 = tf.keras.layers.Dense(100, activation='relu')\n",
    "hidden_layer2 = tf.keras.layers.Dense(100, activation='relu')\n",
    "hidden_layer3 = tf.keras.layers.Dense(50, activation='relu')\n",
    "\n",
    "\n",
    "concat_layer = tf.keras.layers.Concatenate()\n",
    "output_layer = tf.keras.layers.Dense(1)\n",
    "\n",
    "input = tf.keras.Input(shape=(X_train.shape[1],))\n",
    "norm_output = norm_layer(input)\n",
    "hidden1_output = hidden_layer1(norm_output)\n",
    "hidden2_output = hidden_layer2(hidden1_output)\n",
    "hidden3_output = hidden_layer3(hidden2_output)\n",
    "\n",
    "concat_output = concat_layer([norm_output, hidden3_output])\n",
    "output = output_layer(concat_output)\n",
    "\n",
    "model = tf.keras.Model(inputs=input, outputs=output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 47)]         0           []                               \n",
      "                                                                                                  \n",
      " normalization_2 (Normalization  (None, 47)          95          ['input_3[0][0]']                \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 100)          4800        ['normalization_2[0][0]']        \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 100)          10100       ['dense_8[0][0]']                \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 50)           5050        ['dense_9[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 97)           0           ['normalization_2[0][0]',        \n",
      "                                                                  'dense_10[0][0]']               \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, 1)            98          ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 20,143\n",
      "Trainable params: 20,048\n",
      "Non-trainable params: 95\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1877/1877 [==============================] - 10s 5ms/step - loss: 0.7313 - accuracy: 0.6714 - val_loss: 0.7081 - val_accuracy: 0.6804\n",
      "Epoch 2/50\n",
      "1877/1877 [==============================] - 9s 5ms/step - loss: 0.6844 - accuracy: 0.6973 - val_loss: 0.6930 - val_accuracy: 0.6961\n",
      "Epoch 3/50\n",
      "1877/1877 [==============================] - 9s 5ms/step - loss: 0.6716 - accuracy: 0.7056 - val_loss: 0.6843 - val_accuracy: 0.6985\n",
      "Epoch 4/50\n",
      "1877/1877 [==============================] - 9s 5ms/step - loss: 0.6599 - accuracy: 0.7120 - val_loss: 0.6926 - val_accuracy: 0.6981\n",
      "Epoch 5/50\n",
      "1877/1877 [==============================] - 9s 5ms/step - loss: 0.6510 - accuracy: 0.7179 - val_loss: 0.6799 - val_accuracy: 0.7037\n",
      "Epoch 6/50\n",
      "1877/1877 [==============================] - 9s 5ms/step - loss: 0.6416 - accuracy: 0.7229 - val_loss: 0.6739 - val_accuracy: 0.7043\n",
      "Epoch 7/50\n",
      "1877/1877 [==============================] - 9s 5ms/step - loss: 0.6341 - accuracy: 0.7282 - val_loss: 0.6727 - val_accuracy: 0.7053\n",
      "Epoch 8/50\n",
      "1877/1877 [==============================] - 9s 5ms/step - loss: 0.6265 - accuracy: 0.7313 - val_loss: 0.6677 - val_accuracy: 0.7100\n",
      "Epoch 9/50\n",
      "1877/1877 [==============================] - 8s 4ms/step - loss: 0.6199 - accuracy: 0.7361 - val_loss: 0.6630 - val_accuracy: 0.7097\n",
      "Epoch 10/50\n",
      "1877/1877 [==============================] - 9s 5ms/step - loss: 0.6147 - accuracy: 0.7383 - val_loss: 0.6594 - val_accuracy: 0.7146\n",
      "Epoch 11/50\n",
      "1877/1877 [==============================] - 9s 5ms/step - loss: 0.6082 - accuracy: 0.7418 - val_loss: 0.6630 - val_accuracy: 0.7171\n",
      "Epoch 12/50\n",
      "1877/1877 [==============================] - 9s 5ms/step - loss: 0.6030 - accuracy: 0.7433 - val_loss: 0.6584 - val_accuracy: 0.7183\n",
      "Epoch 13/50\n",
      "1877/1877 [==============================] - 9s 5ms/step - loss: 0.5986 - accuracy: 0.7464 - val_loss: 0.6607 - val_accuracy: 0.7171\n",
      "Epoch 14/50\n",
      "1877/1877 [==============================] - 8s 4ms/step - loss: 0.5937 - accuracy: 0.7489 - val_loss: 0.6575 - val_accuracy: 0.7179\n",
      "Epoch 15/50\n",
      "1877/1877 [==============================] - 8s 5ms/step - loss: 0.5884 - accuracy: 0.7518 - val_loss: 0.6592 - val_accuracy: 0.7174\n",
      "Epoch 16/50\n",
      "1877/1877 [==============================] - 7s 4ms/step - loss: 0.5851 - accuracy: 0.7532 - val_loss: 0.6548 - val_accuracy: 0.7224\n",
      "Epoch 17/50\n",
      "1877/1877 [==============================] - 8s 4ms/step - loss: 0.5804 - accuracy: 0.7567 - val_loss: 0.6529 - val_accuracy: 0.7231\n",
      "Epoch 18/50\n",
      "1877/1877 [==============================] - 8s 4ms/step - loss: 0.5779 - accuracy: 0.7568 - val_loss: 0.6500 - val_accuracy: 0.7254\n",
      "Epoch 19/50\n",
      "1877/1877 [==============================] - 8s 4ms/step - loss: 0.5737 - accuracy: 0.7575 - val_loss: 0.6550 - val_accuracy: 0.7263\n",
      "Epoch 20/50\n",
      "1877/1877 [==============================] - 7s 4ms/step - loss: 0.5709 - accuracy: 0.7598 - val_loss: 0.6530 - val_accuracy: 0.7221\n",
      "Epoch 21/50\n",
      "1877/1877 [==============================] - 8s 4ms/step - loss: 0.5660 - accuracy: 0.7626 - val_loss: 0.6536 - val_accuracy: 0.7257\n",
      "Epoch 22/50\n",
      "1877/1877 [==============================] - 8s 4ms/step - loss: 0.5643 - accuracy: 0.7631 - val_loss: 0.6473 - val_accuracy: 0.7222\n",
      "Epoch 23/50\n",
      "1877/1877 [==============================] - 8s 4ms/step - loss: 0.5615 - accuracy: 0.7640 - val_loss: 0.6443 - val_accuracy: 0.7286\n",
      "Epoch 24/50\n",
      "1877/1877 [==============================] - 9s 5ms/step - loss: 0.5583 - accuracy: 0.7651 - val_loss: 0.6521 - val_accuracy: 0.7219\n",
      "Epoch 25/50\n",
      "1877/1877 [==============================] - 8s 5ms/step - loss: 0.5558 - accuracy: 0.7673 - val_loss: 0.6504 - val_accuracy: 0.7307\n",
      "Epoch 26/50\n",
      "1877/1877 [==============================] - 7s 4ms/step - loss: 0.5535 - accuracy: 0.7671 - val_loss: 0.6511 - val_accuracy: 0.7299\n",
      "Epoch 27/50\n",
      "1877/1877 [==============================] - 8s 4ms/step - loss: 0.5516 - accuracy: 0.7687 - val_loss: 0.6492 - val_accuracy: 0.7283\n",
      "Epoch 28/50\n",
      "1877/1877 [==============================] - 7s 4ms/step - loss: 0.5493 - accuracy: 0.7685 - val_loss: 0.6448 - val_accuracy: 0.7274\n",
      "Epoch 29/50\n",
      "1877/1877 [==============================] - 7s 4ms/step - loss: 0.5477 - accuracy: 0.7695 - val_loss: 0.6521 - val_accuracy: 0.7289\n",
      "Epoch 30/50\n",
      "1877/1877 [==============================] - 7s 4ms/step - loss: 0.5451 - accuracy: 0.7714 - val_loss: 0.6432 - val_accuracy: 0.7287\n",
      "Epoch 31/50\n",
      "1877/1877 [==============================] - 7s 4ms/step - loss: 0.5438 - accuracy: 0.7710 - val_loss: 0.6458 - val_accuracy: 0.7275\n",
      "Epoch 32/50\n",
      "1877/1877 [==============================] - 8s 4ms/step - loss: 0.5412 - accuracy: 0.7725 - val_loss: 0.6564 - val_accuracy: 0.7314\n",
      "Epoch 33/50\n",
      "1877/1877 [==============================] - 8s 4ms/step - loss: 0.5407 - accuracy: 0.7722 - val_loss: 0.6438 - val_accuracy: 0.7338\n",
      "Epoch 34/50\n",
      "1877/1877 [==============================] - 8s 4ms/step - loss: 0.5388 - accuracy: 0.7742 - val_loss: 0.6459 - val_accuracy: 0.7306\n",
      "Epoch 35/50\n",
      "1877/1877 [==============================] - 8s 4ms/step - loss: 0.5379 - accuracy: 0.7730 - val_loss: 0.6401 - val_accuracy: 0.7374\n",
      "Epoch 36/50\n",
      "1877/1877 [==============================] - 8s 4ms/step - loss: 0.5357 - accuracy: 0.7767 - val_loss: 0.6498 - val_accuracy: 0.7266\n",
      "Epoch 37/50\n",
      "1877/1877 [==============================] - 7s 4ms/step - loss: 0.5350 - accuracy: 0.7767 - val_loss: 0.6490 - val_accuracy: 0.7365\n",
      "Epoch 38/50\n",
      "1877/1877 [==============================] - 8s 4ms/step - loss: 0.5325 - accuracy: 0.7767 - val_loss: 0.6429 - val_accuracy: 0.7331\n",
      "Epoch 39/50\n",
      "1877/1877 [==============================] - 8s 4ms/step - loss: 0.5315 - accuracy: 0.7776 - val_loss: 0.6472 - val_accuracy: 0.7356\n",
      "Epoch 40/50\n",
      "1877/1877 [==============================] - 8s 4ms/step - loss: 0.5294 - accuracy: 0.7769 - val_loss: 0.6476 - val_accuracy: 0.7292\n",
      "Epoch 41/50\n",
      "1877/1877 [==============================] - 8s 4ms/step - loss: 0.5286 - accuracy: 0.7784 - val_loss: 0.6394 - val_accuracy: 0.7344\n",
      "Epoch 42/50\n",
      "1877/1877 [==============================] - 8s 4ms/step - loss: 0.5276 - accuracy: 0.7786 - val_loss: 0.6386 - val_accuracy: 0.7390\n",
      "Epoch 43/50\n",
      "1877/1877 [==============================] - 8s 4ms/step - loss: 0.5259 - accuracy: 0.7788 - val_loss: 0.6463 - val_accuracy: 0.7301\n",
      "Epoch 44/50\n",
      "1877/1877 [==============================] - 7s 4ms/step - loss: 0.5246 - accuracy: 0.7788 - val_loss: 0.6358 - val_accuracy: 0.7404\n",
      "Epoch 45/50\n",
      "1877/1877 [==============================] - 8s 4ms/step - loss: 0.5232 - accuracy: 0.7807 - val_loss: 0.6350 - val_accuracy: 0.7377\n",
      "Epoch 46/50\n",
      "1877/1877 [==============================] - 8s 5ms/step - loss: 0.5221 - accuracy: 0.7816 - val_loss: 0.6505 - val_accuracy: 0.7268\n",
      "Epoch 47/50\n",
      "1877/1877 [==============================] - 9s 5ms/step - loss: 0.5214 - accuracy: 0.7805 - val_loss: 0.6391 - val_accuracy: 0.7368\n",
      "Epoch 48/50\n",
      "1877/1877 [==============================] - 8s 4ms/step - loss: 0.5208 - accuracy: 0.7813 - val_loss: 0.6428 - val_accuracy: 0.7398\n",
      "Epoch 49/50\n",
      "1877/1877 [==============================] - 8s 4ms/step - loss: 0.5185 - accuracy: 0.7819 - val_loss: 0.6511 - val_accuracy: 0.7338\n",
      "Epoch 50/50\n",
      "1877/1877 [==============================] - 8s 4ms/step - loss: 0.5169 - accuracy: 0.7834 - val_loss: 0.6503 - val_accuracy: 0.7275\n",
      "403/403 [==============================] - 1s 2ms/step - loss: 0.6296 - accuracy: 0.7333\n",
      "Test Accuracy: 0.733307421207428\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Assuming you have your features (X) and target (y) prepared\n",
    "# X = ... (your feature DataFrame)\n",
    "# y = ... (your target variable)\n",
    "\n",
    "# Step 1: Split the data\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)  # 70% train, 30% temp\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)  # 15% val, 15% test\n",
    "\n",
    "# Step 2: Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Step 3: Define the model\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),  # Input layer\n",
    "    layers.Dense(32, activation='relu'),  # Hidden layer\n",
    "    layers.Dense(16, activation='relu'),  # Hidden layer\n",
    "    layers.Dense(len(np.unique(y)), activation='softmax')  # Output layer (softmax for multi-class)\n",
    "])\n",
    "\n",
    "# Step 4: Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',  # Use 'categorical_crossentropy' if one-hot encoded\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Step 5: Train the model\n",
    "history = model.fit(X_train, y_train, \n",
    "                    validation_data=(X_val, y_val), \n",
    "                    epochs=50,  # Adjust the number of epochs as needed\n",
    "                    batch_size=32)  # Adjust the batch size as needed\n",
    "\n",
    "# Step 6: Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print('Test Accuracy:', test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1877/1877 [==============================] - 10s 5ms/step - loss: 0.7266 - accuracy: 0.6726 - val_loss: 0.7133 - val_accuracy: 0.6696\n",
      "Epoch 2/30\n",
      "1877/1877 [==============================] - 9s 5ms/step - loss: 0.6825 - accuracy: 0.6981 - val_loss: 0.6903 - val_accuracy: 0.6993\n",
      "Epoch 3/30\n",
      "1877/1877 [==============================] - 9s 5ms/step - loss: 0.6686 - accuracy: 0.7083 - val_loss: 0.6775 - val_accuracy: 0.7008\n",
      "Epoch 4/30\n",
      "1877/1877 [==============================] - 9s 5ms/step - loss: 0.6558 - accuracy: 0.7164 - val_loss: 0.6858 - val_accuracy: 0.7041\n",
      "Epoch 5/30\n",
      "1877/1877 [==============================] - 9s 5ms/step - loss: 0.6445 - accuracy: 0.7224 - val_loss: 0.6689 - val_accuracy: 0.7103\n",
      "Epoch 6/30\n",
      "1877/1877 [==============================] - 9s 5ms/step - loss: 0.6333 - accuracy: 0.7286 - val_loss: 0.6580 - val_accuracy: 0.7170\n",
      "Epoch 7/30\n",
      "1877/1877 [==============================] - 10s 5ms/step - loss: 0.6221 - accuracy: 0.7348 - val_loss: 0.6519 - val_accuracy: 0.7210\n",
      "Epoch 8/30\n",
      "1877/1877 [==============================] - 9s 5ms/step - loss: 0.6125 - accuracy: 0.7392 - val_loss: 0.6458 - val_accuracy: 0.7214\n",
      "Epoch 9/30\n",
      "1877/1877 [==============================] - 9s 5ms/step - loss: 0.6035 - accuracy: 0.7446 - val_loss: 0.6397 - val_accuracy: 0.7270\n",
      "Epoch 10/30\n",
      "1877/1877 [==============================] - 9s 5ms/step - loss: 0.5953 - accuracy: 0.7473 - val_loss: 0.6401 - val_accuracy: 0.7244\n",
      "Epoch 11/30\n",
      "1877/1877 [==============================] - 9s 5ms/step - loss: 0.5887 - accuracy: 0.7518 - val_loss: 0.6367 - val_accuracy: 0.7298\n",
      "Epoch 12/30\n",
      "1877/1877 [==============================] - 9s 5ms/step - loss: 0.5826 - accuracy: 0.7548 - val_loss: 0.6318 - val_accuracy: 0.7327\n",
      "Epoch 13/30\n",
      "1877/1877 [==============================] - 9s 5ms/step - loss: 0.5758 - accuracy: 0.7576 - val_loss: 0.6323 - val_accuracy: 0.7351\n",
      "Epoch 14/30\n",
      "1877/1877 [==============================] - 10s 5ms/step - loss: 0.5708 - accuracy: 0.7606 - val_loss: 0.6360 - val_accuracy: 0.7366\n",
      "Epoch 15/30\n",
      "1877/1877 [==============================] - 9s 5ms/step - loss: 0.5677 - accuracy: 0.7638 - val_loss: 0.6353 - val_accuracy: 0.7323\n",
      "Epoch 16/30\n",
      "1877/1877 [==============================] - 9s 5ms/step - loss: 0.5610 - accuracy: 0.7646 - val_loss: 0.6256 - val_accuracy: 0.7389\n",
      "Epoch 17/30\n",
      "1877/1877 [==============================] - 10s 5ms/step - loss: 0.5583 - accuracy: 0.7669 - val_loss: 0.6228 - val_accuracy: 0.7397\n",
      "Epoch 18/30\n",
      "1877/1877 [==============================] - 9s 5ms/step - loss: 0.5531 - accuracy: 0.7690 - val_loss: 0.6179 - val_accuracy: 0.7423\n",
      "Epoch 19/30\n",
      "1877/1877 [==============================] - 9s 5ms/step - loss: 0.5485 - accuracy: 0.7722 - val_loss: 0.6242 - val_accuracy: 0.7432\n",
      "Epoch 20/30\n",
      "1877/1877 [==============================] - 9s 5ms/step - loss: 0.5447 - accuracy: 0.7733 - val_loss: 0.6281 - val_accuracy: 0.7408\n",
      "Epoch 21/30\n",
      "1877/1877 [==============================] - 9s 5ms/step - loss: 0.5405 - accuracy: 0.7745 - val_loss: 0.6135 - val_accuracy: 0.7456\n",
      "Epoch 22/30\n",
      "1877/1877 [==============================] - 9s 5ms/step - loss: 0.5381 - accuracy: 0.7758 - val_loss: 0.6181 - val_accuracy: 0.7419\n",
      "Epoch 23/30\n",
      "1877/1877 [==============================] - 9s 5ms/step - loss: 0.5342 - accuracy: 0.7776 - val_loss: 0.6093 - val_accuracy: 0.7453\n",
      "Epoch 24/30\n",
      "1877/1877 [==============================] - 9s 5ms/step - loss: 0.5304 - accuracy: 0.7798 - val_loss: 0.6121 - val_accuracy: 0.7461\n",
      "Epoch 25/30\n",
      "1877/1877 [==============================] - 9s 5ms/step - loss: 0.5280 - accuracy: 0.7811 - val_loss: 0.6203 - val_accuracy: 0.7452\n",
      "Epoch 26/30\n",
      "1877/1877 [==============================] - 9s 5ms/step - loss: 0.5249 - accuracy: 0.7819 - val_loss: 0.6196 - val_accuracy: 0.7399\n",
      "Epoch 27/30\n",
      "1877/1877 [==============================] - 9s 5ms/step - loss: 0.5226 - accuracy: 0.7825 - val_loss: 0.6148 - val_accuracy: 0.7488\n",
      "Epoch 28/30\n",
      "1877/1877 [==============================] - 10s 5ms/step - loss: 0.5200 - accuracy: 0.7838 - val_loss: 0.6157 - val_accuracy: 0.7439\n",
      "Epoch 29/30\n",
      "1877/1877 [==============================] - 9s 5ms/step - loss: 0.5177 - accuracy: 0.7841 - val_loss: 0.6098 - val_accuracy: 0.7488\n",
      "Epoch 30/30\n",
      "1877/1877 [==============================] - 9s 5ms/step - loss: 0.5156 - accuracy: 0.7856 - val_loss: 0.6101 - val_accuracy: 0.7466\n",
      "403/403 [==============================] - 1s 3ms/step - loss: 0.5960 - accuracy: 0.7521\n",
      "Test Accuracy: 0.7521181702613831\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "\n",
    "# Assuming you have your features (X) and target (y) prepared\n",
    "# X = ... (your feature DataFrame)\n",
    "# y = ... (your target variable)\n",
    "\n",
    "# Step 1: Split the data\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)  # 70% train, 30% temp\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)  # 15% val, 15% test\n",
    "\n",
    "# Step 2: Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Step 3: Define the model\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),  # Input layer\n",
    "    layers.Dense(32, activation='relu'),  # Hidden layer\n",
    "    layers.Dense(32, activation='relu'),  # Hidden layer\n",
    "    layers.Dense(32, activation='relu'),  # Hidden layer\n",
    "    layers.Dense(16, activation='relu'),  # Hidden layer\n",
    "    layers.Dense(len(np.unique(y)), activation='softmax')  # Output layer (softmax for multi-class)\n",
    "])\n",
    "\n",
    "# Step 4: Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',  # Use 'categorical_crossentropy' if one-hot encoded\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Step 5: Train the model\n",
    "history = model.fit(X_train, y_train, \n",
    "                    validation_data=(X_val, y_val), \n",
    "                    epochs=30,  # Adjust the number of epochs as needed\n",
    "                    batch_size=32)  # Adjust the batch size as needed\n",
    "\n",
    "# Step 6: Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print('Test Accuracy:', test_accuracy) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2332272d0c0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#lets sgraph the learning curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1501/1501 [==============================] - 8s 5ms/step - loss: nan - accuracy: 0.1758 - val_loss: nan - val_accuracy: 0.1861\n",
      "Epoch 2/50\n",
      "1501/1501 [==============================] - 9s 6ms/step - loss: nan - accuracy: 0.1758 - val_loss: nan - val_accuracy: 0.1861\n",
      "Epoch 3/50\n",
      "1501/1501 [==============================] - 8s 6ms/step - loss: nan - accuracy: 0.1758 - val_loss: nan - val_accuracy: 0.1861\n",
      "Epoch 4/50\n",
      "1501/1501 [==============================] - 8s 6ms/step - loss: nan - accuracy: 0.1758 - val_loss: nan - val_accuracy: 0.1861\n",
      "Epoch 5/50\n",
      "1501/1501 [==============================] - 8s 6ms/step - loss: nan - accuracy: 0.1758 - val_loss: nan - val_accuracy: 0.1861\n",
      "Epoch 6/50\n",
      "1501/1501 [==============================] - 8s 5ms/step - loss: nan - accuracy: 0.1758 - val_loss: nan - val_accuracy: 0.1861\n",
      "Epoch 7/50\n",
      "1501/1501 [==============================] - 8s 5ms/step - loss: nan - accuracy: 0.1758 - val_loss: nan - val_accuracy: 0.1861\n",
      "Epoch 8/50\n",
      "1501/1501 [==============================] - 8s 6ms/step - loss: nan - accuracy: 0.1758 - val_loss: nan - val_accuracy: 0.1861\n",
      "Epoch 9/50\n",
      "1501/1501 [==============================] - 8s 5ms/step - loss: nan - accuracy: 0.1758 - val_loss: nan - val_accuracy: 0.1861\n",
      "Epoch 10/50\n",
      "1501/1501 [==============================] - 8s 5ms/step - loss: nan - accuracy: 0.1758 - val_loss: nan - val_accuracy: 0.1861\n",
      "Epoch 11/50\n",
      "1501/1501 [==============================] - 8s 6ms/step - loss: nan - accuracy: 0.1758 - val_loss: nan - val_accuracy: 0.1861\n",
      "Epoch 12/50\n",
      "1501/1501 [==============================] - 9s 6ms/step - loss: nan - accuracy: 0.1758 - val_loss: nan - val_accuracy: 0.1861\n",
      "Epoch 13/50\n",
      "1501/1501 [==============================] - 9s 6ms/step - loss: nan - accuracy: 0.1758 - val_loss: nan - val_accuracy: 0.1861\n",
      "Epoch 14/50\n",
      "1501/1501 [==============================] - 8s 5ms/step - loss: nan - accuracy: 0.1758 - val_loss: nan - val_accuracy: 0.1861\n",
      "Epoch 15/50\n",
      "1501/1501 [==============================] - 8s 6ms/step - loss: nan - accuracy: 0.1758 - val_loss: nan - val_accuracy: 0.1861\n",
      "Epoch 16/50\n",
      "1501/1501 [==============================] - 8s 6ms/step - loss: nan - accuracy: 0.1758 - val_loss: nan - val_accuracy: 0.1861\n",
      "Epoch 17/50\n",
      "1501/1501 [==============================] - 8s 5ms/step - loss: nan - accuracy: 0.1758 - val_loss: nan - val_accuracy: 0.1861\n",
      "Epoch 18/50\n",
      "1501/1501 [==============================] - 8s 6ms/step - loss: nan - accuracy: 0.1758 - val_loss: nan - val_accuracy: 0.1861\n",
      "Epoch 19/50\n",
      "1501/1501 [==============================] - 8s 6ms/step - loss: nan - accuracy: 0.1758 - val_loss: nan - val_accuracy: 0.1861\n",
      "Epoch 20/50\n",
      "1501/1501 [==============================] - 9s 6ms/step - loss: nan - accuracy: 0.1758 - val_loss: nan - val_accuracy: 0.1861\n",
      "Epoch 21/50\n",
      "1501/1501 [==============================] - 8s 5ms/step - loss: nan - accuracy: 0.1758 - val_loss: nan - val_accuracy: 0.1861\n",
      "Epoch 22/50\n",
      "1501/1501 [==============================] - 8s 5ms/step - loss: nan - accuracy: 0.1758 - val_loss: nan - val_accuracy: 0.1861\n",
      "Epoch 23/50\n",
      "1501/1501 [==============================] - 8s 5ms/step - loss: nan - accuracy: 0.1758 - val_loss: nan - val_accuracy: 0.1861\n",
      "Epoch 24/50\n",
      "1501/1501 [==============================] - 8s 5ms/step - loss: nan - accuracy: 0.1758 - val_loss: nan - val_accuracy: 0.1861\n",
      "Epoch 25/50\n",
      "1501/1501 [==============================] - 7s 5ms/step - loss: nan - accuracy: 0.1758 - val_loss: nan - val_accuracy: 0.1861\n",
      "Epoch 26/50\n",
      "1501/1501 [==============================] - 7s 5ms/step - loss: nan - accuracy: 0.1758 - val_loss: nan - val_accuracy: 0.1861\n",
      "Epoch 27/50\n",
      "1501/1501 [==============================] - 7s 5ms/step - loss: nan - accuracy: 0.1758 - val_loss: nan - val_accuracy: 0.1861\n",
      "Epoch 28/50\n",
      "1501/1501 [==============================] - 7s 5ms/step - loss: nan - accuracy: 0.1758 - val_loss: nan - val_accuracy: 0.1861\n",
      "Epoch 29/50\n",
      "1501/1501 [==============================] - 7s 5ms/step - loss: nan - accuracy: 0.1758 - val_loss: nan - val_accuracy: 0.1861\n",
      "Epoch 30/50\n",
      "1501/1501 [==============================] - 8s 5ms/step - loss: nan - accuracy: 0.1758 - val_loss: nan - val_accuracy: 0.1861\n",
      "Epoch 31/50\n",
      "1501/1501 [==============================] - 8s 5ms/step - loss: nan - accuracy: 0.1758 - val_loss: nan - val_accuracy: 0.1861\n",
      "Epoch 32/50\n",
      "1501/1501 [==============================] - 8s 6ms/step - loss: nan - accuracy: 0.1758 - val_loss: nan - val_accuracy: 0.1861\n",
      "Epoch 33/50\n",
      "1501/1501 [==============================] - 8s 5ms/step - loss: nan - accuracy: 0.1758 - val_loss: nan - val_accuracy: 0.1861\n",
      "Epoch 34/50\n",
      "1501/1501 [==============================] - 8s 5ms/step - loss: nan - accuracy: 0.1758 - val_loss: nan - val_accuracy: 0.1861\n",
      "Epoch 35/50\n",
      "1501/1501 [==============================] - 8s 5ms/step - loss: nan - accuracy: 0.1758 - val_loss: nan - val_accuracy: 0.1861\n",
      "Epoch 36/50\n",
      "1501/1501 [==============================] - 8s 6ms/step - loss: nan - accuracy: 0.1758 - val_loss: nan - val_accuracy: 0.1861\n",
      "Epoch 37/50\n",
      "1501/1501 [==============================] - 9s 6ms/step - loss: nan - accuracy: 0.1758 - val_loss: nan - val_accuracy: 0.1861\n",
      "Epoch 38/50\n",
      "1501/1501 [==============================] - 8s 6ms/step - loss: nan - accuracy: 0.1758 - val_loss: nan - val_accuracy: 0.1861\n",
      "Epoch 39/50\n",
      "1501/1501 [==============================] - 9s 6ms/step - loss: nan - accuracy: 0.1758 - val_loss: nan - val_accuracy: 0.1861\n",
      "Epoch 40/50\n",
      "1501/1501 [==============================] - 8s 6ms/step - loss: nan - accuracy: 0.1758 - val_loss: nan - val_accuracy: 0.1861\n",
      "Epoch 41/50\n",
      "1501/1501 [==============================] - 8s 5ms/step - loss: nan - accuracy: 0.1758 - val_loss: nan - val_accuracy: 0.1861\n",
      "Epoch 42/50\n",
      "1501/1501 [==============================] - 8s 5ms/step - loss: nan - accuracy: 0.1758 - val_loss: nan - val_accuracy: 0.1861\n",
      "Epoch 43/50\n",
      "1501/1501 [==============================] - 9s 6ms/step - loss: nan - accuracy: 0.1758 - val_loss: nan - val_accuracy: 0.1861\n",
      "Epoch 44/50\n",
      "1501/1501 [==============================] - 9s 6ms/step - loss: nan - accuracy: 0.1758 - val_loss: nan - val_accuracy: 0.1861\n",
      "Epoch 45/50\n",
      "1501/1501 [==============================] - 8s 6ms/step - loss: nan - accuracy: 0.1758 - val_loss: nan - val_accuracy: 0.1861\n",
      "Epoch 46/50\n",
      "1501/1501 [==============================] - 9s 6ms/step - loss: nan - accuracy: 0.1758 - val_loss: nan - val_accuracy: 0.1861\n",
      "Epoch 47/50\n",
      "1501/1501 [==============================] - 38s 25ms/step - loss: nan - accuracy: 0.1758 - val_loss: nan - val_accuracy: 0.1861\n",
      "Epoch 48/50\n",
      "1501/1501 [==============================] - 53s 36ms/step - loss: nan - accuracy: 0.1758 - val_loss: nan - val_accuracy: 0.1861\n",
      "Epoch 49/50\n",
      "1501/1501 [==============================] - 12s 8ms/step - loss: nan - accuracy: 0.1758 - val_loss: nan - val_accuracy: 0.1861\n",
      "Epoch 50/50\n",
      "1501/1501 [==============================] - 9s 6ms/step - loss: nan - accuracy: 0.1758 - val_loss: nan - val_accuracy: 0.1861\n",
      "403/403 [==============================] - 1s 3ms/step - loss: nan - accuracy: 0.1794\n",
      "Accuracy: [nan, 0.1794014722108841]\n",
      "403/403 [==============================] - 1s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "norm_layer.adapt(X_train)\n",
    "history = model.fit(X_train, y_train, epochs=50, validation_split=0.2)\n",
    "accuracy = model.evaluate(X_test, y_test)\n",
    "print('Accuracy:', accuracy)\n",
    "y_pred = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets change the credit score column to a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 50 columns):\n",
      " #   Column                    Non-Null Count   Dtype   \n",
      "---  ------                    --------------   -----   \n",
      " 0   ID                        100000 non-null  object  \n",
      " 1   Month                     100000 non-null  object  \n",
      " 2   Name                      90015 non-null   object  \n",
      " 3   Age                       100000 non-null  float64 \n",
      " 4   SSN                       100000 non-null  object  \n",
      " 5   Annual_Income             100000 non-null  float64 \n",
      " 6   Monthly_Inhand_Salary     99336 non-null   float64 \n",
      " 7   Num_Bank_Accounts         100000 non-null  float64 \n",
      " 8   Num_Credit_Card           100000 non-null  float64 \n",
      " 9   Interest_Rate             100000 non-null  float64 \n",
      " 10  Num_of_Loan               100000 non-null  float64 \n",
      " 11  Delay_from_due_date       100000 non-null  float64 \n",
      " 12  Num_of_Delayed_Payment    92998 non-null   float64 \n",
      " 13  Changed_Credit_Limit      100000 non-null  float64 \n",
      " 14  Num_Credit_Inquiries      100000 non-null  float64 \n",
      " 15  Credit_Mix                100000 non-null  category\n",
      " 16  Outstanding_Debt          100000 non-null  float64 \n",
      " 17  Credit_Utilization_Ratio  100000 non-null  float64 \n",
      " 18  Credit_History_Age        100000 non-null  int32   \n",
      " 19  Payment_of_Min_Amount     100000 non-null  object  \n",
      " 20  Total_EMI_per_month       100000 non-null  float64 \n",
      " 21  Amount_invested_monthly   95521 non-null   float64 \n",
      " 22  Monthly_Balance           97132 non-null   float64 \n",
      " 23  Credit_Score              100000 non-null  object  \n",
      " 24  Charge                    100000 non-null  int64   \n",
      " 25  Payment                   100000 non-null  int64   \n",
      " 26  Auto Loan                 100000 non-null  int32   \n",
      " 27  Credit-Builder Loan       100000 non-null  int32   \n",
      " 28  Debt Consolidation Loan   100000 non-null  int32   \n",
      " 29  Home Equity Loan          100000 non-null  int32   \n",
      " 30  Mortgage Loan             100000 non-null  int32   \n",
      " 31  Not Specified             100000 non-null  int32   \n",
      " 32  Payday Loan               100000 non-null  int32   \n",
      " 33  Personal Loan             100000 non-null  int32   \n",
      " 34  Student Loan              100000 non-null  int32   \n",
      " 35  Occupation_Accountant     100000 non-null  float64 \n",
      " 36  Occupation_Architect      100000 non-null  float64 \n",
      " 37  Occupation_Developer      100000 non-null  float64 \n",
      " 38  Occupation_Doctor         100000 non-null  float64 \n",
      " 39  Occupation_Engineer       100000 non-null  float64 \n",
      " 40  Occupation_Entrepreneur   100000 non-null  float64 \n",
      " 41  Occupation_Journalist     100000 non-null  float64 \n",
      " 42  Occupation_Lawyer         100000 non-null  float64 \n",
      " 43  Occupation_Manager        100000 non-null  float64 \n",
      " 44  Occupation_Mechanic       100000 non-null  float64 \n",
      " 45  Occupation_Media_Manager  100000 non-null  float64 \n",
      " 46  Occupation_Musician       100000 non-null  float64 \n",
      " 47  Occupation_Scientist      100000 non-null  float64 \n",
      " 48  Occupation_Teacher        100000 non-null  float64 \n",
      " 49  Occupation_Writer         100000 non-null  float64 \n",
      "dtypes: category(1), float64(31), int32(10), int64(2), object(6)\n",
      "memory usage: 33.7+ MB\n"
     ]
    }
   ],
   "source": [
    "train_copy.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 85763 entries, 0 to 98303\n",
      "Data columns (total 48 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Age                       85763 non-null  float64\n",
      " 1   Annual_Income             85763 non-null  float64\n",
      " 2   Monthly_Inhand_Salary     85763 non-null  float64\n",
      " 3   Num_Bank_Accounts         85763 non-null  float64\n",
      " 4   Num_Credit_Card           85763 non-null  float64\n",
      " 5   Interest_Rate             85763 non-null  float64\n",
      " 6   Num_of_Loan               85763 non-null  float64\n",
      " 7   Delay_from_due_date       85763 non-null  float64\n",
      " 8   Num_of_Delayed_Payment    85763 non-null  float64\n",
      " 9   Changed_Credit_Limit      85763 non-null  float64\n",
      " 10  Num_Credit_Inquiries      85763 non-null  float64\n",
      " 11  Credit_Mix                85763 non-null  int8   \n",
      " 12  Outstanding_Debt          85763 non-null  float64\n",
      " 13  Credit_Utilization_Ratio  85763 non-null  float64\n",
      " 14  Credit_History_Age        85763 non-null  int32  \n",
      " 15  Payment_of_Min_Amount     85763 non-null  int8   \n",
      " 16  Total_EMI_per_month       85763 non-null  float64\n",
      " 17  Amount_invested_monthly   85763 non-null  float64\n",
      " 18  Monthly_Balance           85763 non-null  float64\n",
      " 19  Credit_Score              85763 non-null  int8   \n",
      " 20  Charge                    85763 non-null  int64  \n",
      " 21  Payment                   85763 non-null  int64  \n",
      " 22  Auto Loan                 85763 non-null  int32  \n",
      " 23  Credit-Builder Loan       85763 non-null  int32  \n",
      " 24  Debt Consolidation Loan   85763 non-null  int32  \n",
      " 25  Home Equity Loan          85763 non-null  int32  \n",
      " 26  Mortgage Loan             85763 non-null  int32  \n",
      " 27  Not Specified             85763 non-null  int32  \n",
      " 28  Payday Loan               85763 non-null  int32  \n",
      " 29  Personal Loan             85763 non-null  int32  \n",
      " 30  Student Loan              85763 non-null  int32  \n",
      " 31  Occupation_Accountant     85763 non-null  float64\n",
      " 32  Occupation_Architect      85763 non-null  float64\n",
      " 33  Occupation_Developer      85763 non-null  float64\n",
      " 34  Occupation_Doctor         85763 non-null  float64\n",
      " 35  Occupation_Engineer       85763 non-null  float64\n",
      " 36  Occupation_Entrepreneur   85763 non-null  float64\n",
      " 37  Occupation_Journalist     85763 non-null  float64\n",
      " 38  Occupation_Lawyer         85763 non-null  float64\n",
      " 39  Occupation_Manager        85763 non-null  float64\n",
      " 40  Occupation_Mechanic       85763 non-null  float64\n",
      " 41  Occupation_Media_Manager  85763 non-null  float64\n",
      " 42  Occupation_Musician       85763 non-null  float64\n",
      " 43  Occupation_Scientist      85763 non-null  float64\n",
      " 44  Occupation_Teacher        85763 non-null  float64\n",
      " 45  Occupation_Writer         85763 non-null  float64\n",
      " 46  Month_sin                 85763 non-null  float64\n",
      " 47  Month_cos                 85763 non-null  float64\n",
      "dtypes: float64(33), int32(10), int64(2), int8(3)\n",
      "memory usage: 27.1 MB\n"
     ]
    }
   ],
   "source": [
    "x.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning numeric columns\n",
      "Transforming Credit_History_Age\n",
      "Transforming Payment_Behaviour\n",
      "Transforming Loan Type\n",
      "Transforming HiLo values\n",
      "Credit_Mix\n",
      "Standard    45848\n",
      "Good        30384\n",
      "Bad         23768\n",
      "Name: count, dtype: int64\n",
      "Occupation\n",
      "Lawyer           7096\n",
      "Engineer         6864\n",
      "Architect        6824\n",
      "Mechanic         6776\n",
      "Accountant       6744\n",
      "Scientist        6744\n",
      "Developer        6720\n",
      "Media_Manager    6720\n",
      "Teacher          6672\n",
      "Entrepreneur     6648\n",
      "Doctor           6568\n",
      "Journalist       6536\n",
      "Manager          6432\n",
      "Musician         6352\n",
      "Writer           6304\n",
      "Name: count, dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 47 columns):\n",
      " #   Column                    Non-Null Count   Dtype   \n",
      "---  ------                    --------------   -----   \n",
      " 0   Month                     100000 non-null  object  \n",
      " 1   Age                       100000 non-null  float64 \n",
      " 2   Annual_Income             100000 non-null  float64 \n",
      " 3   Monthly_Inhand_Salary     99336 non-null   float64 \n",
      " 4   Num_Bank_Accounts         100000 non-null  float64 \n",
      " 5   Num_Credit_Card           100000 non-null  float64 \n",
      " 6   Interest_Rate             100000 non-null  float64 \n",
      " 7   Num_of_Loan               100000 non-null  float64 \n",
      " 8   Delay_from_due_date       100000 non-null  float64 \n",
      " 9   Num_of_Delayed_Payment    92998 non-null   float64 \n",
      " 10  Changed_Credit_Limit      100000 non-null  float64 \n",
      " 11  Num_Credit_Inquiries      100000 non-null  float64 \n",
      " 12  Credit_Mix                100000 non-null  category\n",
      " 13  Outstanding_Debt          100000 non-null  float64 \n",
      " 14  Credit_Utilization_Ratio  100000 non-null  float64 \n",
      " 15  Credit_History_Age        100000 non-null  int32   \n",
      " 16  Payment_of_Min_Amount     100000 non-null  object  \n",
      " 17  Total_EMI_per_month       100000 non-null  float64 \n",
      " 18  Amount_invested_monthly   95521 non-null   float64 \n",
      " 19  Monthly_Balance           97132 non-null   float64 \n",
      " 20  Credit_Score              100000 non-null  object  \n",
      " 21  Charge                    100000 non-null  int64   \n",
      " 22  Payment                   100000 non-null  int64   \n",
      " 23  Auto Loan                 100000 non-null  int32   \n",
      " 24  Credit-Builder Loan       100000 non-null  int32   \n",
      " 25  Debt Consolidation Loan   100000 non-null  int32   \n",
      " 26  Home Equity Loan          100000 non-null  int32   \n",
      " 27  Mortgage Loan             100000 non-null  int32   \n",
      " 28  Not Specified             100000 non-null  int32   \n",
      " 29  Payday Loan               100000 non-null  int32   \n",
      " 30  Personal Loan             100000 non-null  int32   \n",
      " 31  Student Loan              100000 non-null  int32   \n",
      " 32  Occupation_Accountant     100000 non-null  float64 \n",
      " 33  Occupation_Architect      100000 non-null  float64 \n",
      " 34  Occupation_Developer      100000 non-null  float64 \n",
      " 35  Occupation_Doctor         100000 non-null  float64 \n",
      " 36  Occupation_Engineer       100000 non-null  float64 \n",
      " 37  Occupation_Entrepreneur   100000 non-null  float64 \n",
      " 38  Occupation_Journalist     100000 non-null  float64 \n",
      " 39  Occupation_Lawyer         100000 non-null  float64 \n",
      " 40  Occupation_Manager        100000 non-null  float64 \n",
      " 41  Occupation_Mechanic       100000 non-null  float64 \n",
      " 42  Occupation_Media_Manager  100000 non-null  float64 \n",
      " 43  Occupation_Musician       100000 non-null  float64 \n",
      " 44  Occupation_Scientist      100000 non-null  float64 \n",
      " 45  Occupation_Teacher        100000 non-null  float64 \n",
      " 46  Occupation_Writer         100000 non-null  float64 \n",
      "dtypes: category(1), float64(31), int32(10), int64(2), object(3)\n",
      "memory usage: 31.4+ MB\n",
      "Converting to category\n",
      "Transforming Month\n",
      "Dropping Nan rows\n"
     ]
    }
   ],
   "source": [
    "x = pipeline.fit_transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let get to the model building\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X = x.drop(columns=['Credit_Score'])\n",
    "y = x['Credit_Score']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8091295983209934\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8080802192036378\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(n_estimators=150, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Scores: [0.69509707 0.7033172  0.70401679 0.69222248 0.70481576]\n",
      "Mean Cross Validation Score: 0.6998938615781062\n"
     ]
    }
   ],
   "source": [
    "#okay lets use cross validation to get a better estimate of the model accuracy\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cv_scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')\n",
    "print(f'Cross Validation Scores: {cv_scores}')\n",
    "mean_cv_score = cv_scores.mean()\n",
    "print(f'Mean Cross Validation Score: {mean_cv_score}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Scores: [0.8097708855593774, 0.8047571853320119, 0.8080219203637847, 0.8091184701492538, 0.8041627798507462]\n",
      "Mean Accuracy: 0.8071662482510348\n"
     ]
    }
   ],
   "source": [
    "# lets use startified Kfold to get a better accuracy\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracy_scores = []\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "      X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "      y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "      \n",
    "      model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "      model.fit(X_train, y_train)\n",
    "      y_pred = model.predict(X_test)\n",
    "      accuracy = accuracy_score(y_test, y_pred)\n",
    "      accuracy_scores.append(accuracy)\n",
    "\n",
    "print(f'Accuracy Scores: {accuracy_scores}')\n",
    "print(f'Mean Accuracy: {np.mean(accuracy_scores)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter grid for RandomizedSearchCV\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [50, 100, 150],           # Number of trees in forest\n",
    "    'max_depth': [10, 15, 20, None],          # Maximum depth of each tree\n",
    "    'max_features': ['sqrt', 'log2'],         # Number of features to consider at each split\n",
    "    'min_samples_split': [2, 5, 10],          # Minimum samples required to split a node\n",
    "    'min_samples_leaf': [1, 2, 4],            # Minimum samples required at each leaf node\n",
    "    'bootstrap': [True, False]                # Whether bootstrap samples are used\n",
    "}\n",
    "\n",
    "param_grid_et = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_depth': [10, 15, 20, None],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'time' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[160], line 6\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomizedSearchCV\n\u001b[0;32m      3\u001b[0m rf_clf \u001b[38;5;241m=\u001b[39m RandomForestClassifier(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m start_time \u001b[38;5;241m=\u001b[39m \u001b[43mtime\u001b[49m\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m      7\u001b[0m rf_random_search \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(\n\u001b[0;32m      8\u001b[0m     rf_clf, param_distributions\u001b[38;5;241m=\u001b[39mparam_grid_rf, n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m      9\u001b[0m )\n\u001b[0;32m     10\u001b[0m rf_random_search\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'time' is not defined"
     ]
    }
   ],
   "source": [
    "# Perform RandomizedSearchCV for RandomForest\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "rf_random_search = RandomizedSearchCV(\n",
    "    rf_clf, param_distributions=param_grid_rf, n_iter=10, cv=5, scoring='accuracy', random_state=42, n_jobs=-1\n",
    ")\n",
    "rf_random_search.fit(X_train, y_train)\n",
    "print(\"RandomForest best params:\", rf_random_search.best_params_)\n",
    "print(\"Training time for RandomForest:\", time.time() - start_time)\n",
    "\n",
    "# Perform RandomizedSearchCV for ExtraTrees\n",
    "start_time = time.time()\n",
    "et_random_search = RandomizedSearchCV(\n",
    "    et_clf, param_distributions=param_grid_et, n_iter=10, cv=5, scoring='accuracy', random_state=42, n_jobs=-1\n",
    ")\n",
    "et_random_search.fit(X_train, y_train)\n",
    "print(\"ExtraTrees best params:\", et_random_search.best_params_)\n",
    "print(\"Training time for ExtraTrees:\", time.time() - start_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoosting Accuracy: 0.7144939365671642\n"
     ]
    }
   ],
   "source": [
    "#lets do a model with gradient boosting\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gb_clf = GradientBoostingClassifier(random_state=42)\n",
    "gb_clf.fit(X_train, y_train)\n",
    "y_pred = gb_clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'GradientBoosting Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Scores: [0.6984201  0.70378359 0.71171224 0.70248368 0.71927472]\n",
      "Mean Cross Validation Score: 0.707134865719064\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'iloc'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m accuracy_scores \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train_index, test_index \u001b[38;5;129;01min\u001b[39;00m skf\u001b[38;5;241m.\u001b[39msplit(X, y):\n\u001b[1;32m---> 18\u001b[0m       X_train, X_test \u001b[38;5;241m=\u001b[39m \u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m[train_index], X\u001b[38;5;241m.\u001b[39miloc[test_index]\n\u001b[0;32m     19\u001b[0m       y_train, y_test \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39miloc[train_index], y\u001b[38;5;241m.\u001b[39miloc[test_index]\n\u001b[0;32m     21\u001b[0m       model \u001b[38;5;241m=\u001b[39m GradientBoostingClassifier(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'iloc'"
     ]
    }
   ],
   "source": [
    "#we usse cross validation and startified kfold on the gradient boosting model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "#import the model \n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gb_clf = GradientBoostingClassifier(random_state=42)\n",
    "cv_scores = cross_val_score(gb_clf, X, y, cv=5, scoring='accuracy')\n",
    "print(f'Cross Validation Scores: {cv_scores}')\n",
    "mean_cv_score = cv_scores.mean()\n",
    "print(f'Mean Cross Validation Score: {mean_cv_score}')\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracy_scores = []\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "      X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "      y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "      \n",
    "      model = GradientBoostingClassifier(random_state=42)\n",
    "      model.fit(X_train, y_train)\n",
    "      y_pred = model.predict(X_test)\n",
    "      accuracy = accuracy_score(y_test, y_pred)\n",
    "      accuracy_scores.append(accuracy)\n",
    "\n",
    "print(f'Accuracy Scores: {accuracy_scores}')\n",
    "print(f'Mean Accuracy: {np.mean(accuracy_scores)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 25\u001b[0m\n\u001b[0;32m     15\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(\n\u001b[0;32m     16\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mrf,\n\u001b[0;32m     17\u001b[0m     param_grid\u001b[38;5;241m=\u001b[39mparam_grid,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     21\u001b[0m     scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Choose appropriate scoring metric\u001b[39;00m\n\u001b[0;32m     22\u001b[0m )\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Fit GridSearchCV on the training data\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Best parameters\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Parameters:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\kb\\anaconda3\\envs\\test-env\\lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\kb\\anaconda3\\envs\\test-env\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1019\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m   1013\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m   1014\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m   1015\u001b[0m     )\n\u001b[0;32m   1017\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m-> 1019\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1021\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m   1022\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m   1023\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\kb\\anaconda3\\envs\\test-env\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1573\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1571\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1572\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1573\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kb\\anaconda3\\envs\\test-env\\lib\\site-packages\\sklearn\\model_selection\\_search.py:965\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    957\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    958\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    959\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    960\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    961\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    962\u001b[0m         )\n\u001b[0;32m    963\u001b[0m     )\n\u001b[1;32m--> 965\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    966\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    967\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    968\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    969\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    976\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    981\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    984\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    985\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    986\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    987\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    988\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\kb\\anaconda3\\envs\\test-env\\lib\\site-packages\\sklearn\\utils\\parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     73\u001b[0m )\n\u001b[1;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kb\\anaconda3\\envs\\test-env\\lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kb\\anaconda3\\envs\\test-env\\lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kb\\anaconda3\\envs\\test-env\\lib\\site-packages\\joblib\\parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,  # 5-fold cross-validation\n",
    "    n_jobs=-1,  # Utilize all available cores\n",
    "    verbose=2,\n",
    "    scoring='accuracy'  # Choose appropriate scoring metric\n",
    ")\n",
    "\n",
    "# Fit GridSearchCV on the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best Parameters:\")\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "# Best cross-validation score\n",
    "print(f\"Best Cross-Validation Accuracy: {grid_search.best_score_ * 100:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
