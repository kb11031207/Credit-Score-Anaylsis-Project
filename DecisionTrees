import time
from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier, AdaBoostClassifier
from sklearn.model_selection import GroupShuffleSplit
from sklearn.tree import DecisionTreeClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score
import pandas as pd

# Assuming train and test datasets are already loaded
# Replace these with your dataset variables
train_X, train_y = None, None  # Replace with your training features and target
val_X, val_y = None, None  # Replace with your validation features and target
test_X, test_y = None, None  # Replace with your test features and target

cleanedData = pd.read_csv('train_transformed.csv')
X = cleanedData.drop('Credit_Score', axis=1)
y = cleanedData['Credit_Score']


grouped_split = GroupShuffleSplit(n_splits=1, test_size=0.3, random_state=42)

for train_idx, temp_idx in grouped_split.split(X, y, groups=X['Customer_ID']):
    train_X, X_temp = X.iloc[train_idx], X.iloc[temp_idx]
    train_y, y_temp = y.iloc[train_idx], y.iloc[temp_idx]

# Then, split the temporary set into validation and test sets (50% each)
grouped_split = GroupShuffleSplit(n_splits=1, test_size=0.5, random_state=42)
for val_idx, test_idx in grouped_split.split(X_temp, y_temp, groups=X_temp['Customer_ID']):
    val_X, test_X = X_temp.iloc[val_idx], X_temp.iloc[test_idx]
    val_y, test_y = y_temp.iloc[val_idx], y_temp.iloc[test_idx]

#drop customer id 
train_X = train_X.drop('Customer_ID', axis=1)
val_X = val_X.drop('Customer_ID', axis=1) 
test_X = test_X.drop('Customer_ID', axis=1)
X_temp = X_temp.drop('Customer_ID', axis=1)

train_X.info()
val_X.info()
test_X.info()
#X_temp.info()






# Models and their best parameters
models = {
    "RandomForest": RandomForestClassifier(
        n_estimators=350, min_samples_split=5, min_samples_leaf=4,
        max_features='sqrt', max_depth=15, bootstrap=True
    ),
    "DecisionTree": DecisionTreeClassifier(
        min_samples_split=10, min_samples_leaf=4, max_depth=10
    ),
    "ExtraTrees": ExtraTreesClassifier(
        n_estimators=100, max_features='sqrt', max_depth=15
    ),
    "GradientBoosting": GradientBoostingClassifier(
        n_estimators=100, max_depth=5, learning_rate=0.1
    ),


}

# Training and evaluating each model
results = []

for model_name, model in models.items():
    print(f"\n=== Training {model_name} ===")
    start_time = time.time()
    
    # Train the model
    model.fit(train_X, train_y)
    training_time = time.time() - start_time
    
    # Validate the model
    val_predictions = model.predict(val_X)
    val_accuracy = accuracy_score(val_y, val_predictions)
    
    # Test the model
    test_predictions = model.predict(test_X)
    test_accuracy = accuracy_score(test_y, test_predictions)

    full_pred = model.predict(X_temp)
    full_accuracy = accuracy_score(y_temp, full_pred)

    
    # Record results
    results.append({
        "Model": model_name,
        "Training Time (s)": training_time,
        "Validation Accuracy": val_accuracy,
        "Test Accuracy": test_accuracy,
        "Full Accuracy": full_accuracy
    })
    
    print(f"Training Time: {training_time:.2f} seconds")
    print(f"Validation Accuracy: {val_accuracy:.6f}")
    print(f"Test Accuracy: {test_accuracy:.6f}")
    print(f"Full Accuracy: {full_accuracy:.6f}")


# Display final results
import pandas as pd
results_df = pd.DataFrame(results)
print("\n=== Final Results ===")
print(results_df)
